{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ihVG4Ecgldhj",
        "t2d972H-lmIE",
        "A0Gu2vV2sEUh",
        "aN11etjfzg5-"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN1LC+N6mwTTsE1WT97CAVV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Welcome to a tutorial on RAG with LangChain!\n",
        "----\n",
        "\n",
        "We will be following [this](https://graphacademy.neo4j.com/courses/llm-fundamentals/) official course by Neo4j which introduces you to LangChain, and creating agents with Neo4j as the vetor store. However, because they use the paid APIs by OpenAI for both embedddings and the LLM, I have adapted the tutorial to open-source offerings:\n",
        "\n",
        "- The embedding size and model embedding sizes must match, which narrow the scope of open-source choices. Because this notebook is meant to give a consolidated overview of RAG agents, we will not worry about the performance of the chat model. We take the simpler/smaller Falcon-7B-instruct as it's small enough to be serviced by the HuggingFace API and is also fine-tuned for chat (it's 40B version is also said to be just as performant as its LLaMA size). This narrows our embedder options, but the all-mpnet-base is fortunately trained for semantic search queries, making it ideal for use in the RAG component in this application (we need to match a query to documents).\n",
        "- Though the vector store given to us by default has embeddings, they cannot work for a differently-sized model. Thus, I have taken a further step to recreate the embeddings through the chosen embedder. Details about it appear in the relevant section.\n",
        "\n",
        "Use the index to navigate through the notebook. I have not explained the details of my tweaks and adaptations, but a general understanding from starter LangChain documentation should get you going. In the index:\n",
        "- The [MAIN CODE] indicates the full code by the tutorial, where you can plug and play your LLMs/Embeddings and run the agent code.\n",
        "- The [DEMO] code is where I plug my choices as justified above, to see a sample of how the main code could run (details in the relevant section).\n",
        "- The [CHAT] cell does away with the agents to allow us to have an actual chat with memory enabled with RAG from the Neo4j vector store.\n",
        "\n",
        "- Finally, the last section has a simple application of RAG on local PDFs, which has been deployed on [Streamlit](https://demo-pdf-rag.streamlit.app/).  \n"
      ],
      "metadata": {
        "id": "5_8koGBwKowj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Installing Prerequisites](#scrollTo=dzncwwjDjJy8)\n",
        "\n",
        ">[Preparing Embeddings](#scrollTo=vA_47m-X_OPM)\n",
        "\n",
        ">>[Cypher with vector semantic search](#scrollTo=tA6A5s9YGlzP)\n",
        "\n",
        ">[LangChain](#scrollTo=rN4Q18Q4lVIp)\n",
        "\n",
        ">>[Prompting](#scrollTo=ihVG4Ecgldhj)\n",
        "\n",
        ">>[Chaining](#scrollTo=t2d972H-lmIE)\n",
        "\n",
        ">>[Chat model](#scrollTo=IN2e0kuJlqcq)\n",
        "\n",
        ">>>[Memory](#scrollTo=0Ojfgat9zy7o)\n",
        "\n",
        ">>>[Memory storage in Neo4j](#scrollTo=uDHHzLiNFlws)\n",
        "\n",
        ">[Agents](#scrollTo=dImrap2jL8b4)\n",
        "\n",
        ">[Retrievers](#scrollTo=R7QlMk5-m3JK)\n",
        "\n",
        ">>>[[Additional] Neo4j index at runtime](#scrollTo=A0Gu2vV2sEUh)\n",
        "\n",
        ">>[Full RetrievalQA chain](#scrollTo=I39pwzoX3DFc)\n",
        "\n",
        ">>>[[MAIN CODE] RetrieverQA + Agents (Optional Exercise)](#scrollTo=2onNUexwrTbU)\n",
        "\n",
        ">>>[[DEMO] With Falcon](#scrollTo=9WxCAmBXKBae)\n",
        "\n",
        ">>>[[CHAT] Falcon + Neo4j RAG without agents](#scrollTo=P61zOYnbPf6v)\n",
        "\n",
        ">[[Optional] Cypher query generation by LLMs](#scrollTo=aN11etjfzg5-)\n",
        "\n",
        ">[PDF RAG](#scrollTo=C-kVR781BedD)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "AYuTjDsAKrdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Prerequisites"
      ],
      "metadata": {
        "id": "dzncwwjDjJy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain langchain-community neo4j transformers sentence-transformers youtube-search\n",
        "# !pip install openai langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QyMrm4jyAoBu",
        "outputId": "e35bb917-580f-4053-87e4-cf839f5b1030"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.3.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting neo4j\n",
            "  Downloading neo4j-5.25.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting youtube-search\n",
            "  Downloading youtube_search-2.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.9)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.4.0,>=0.3.10 (from langchain)\n",
            "  Downloading langchain_core-0.3.10-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.134-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.13.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.10->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain-0.3.3-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.2-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading neo4j-5.25.0-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.6/296.6 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-3.2.0-py3-none-any.whl (255 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading youtube_search-2.1.2-py3-none-any.whl (3.4 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_core-0.3.10-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.4/404.4 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.134-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, python-dotenv, orjson, neo4j, mypy-extensions, marshmallow, jsonpointer, h11, youtube-search, typing-inspect, requests-toolbelt, jsonpatch, httpcore, pydantic-settings, httpx, dataclasses-json, langsmith, sentence-transformers, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed dataclasses-json-0.6.7 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.3 langchain-community-0.3.2 langchain-core-0.3.10 langchain-text-splitters-0.3.0 langsmith-0.1.134 marshmallow-3.22.0 mypy-extensions-1.0.0 neo4j-5.25.0 orjson-3.10.7 pydantic-settings-2.5.2 python-dotenv-1.0.1 requests-toolbelt-1.0.0 sentence-transformers-3.2.0 tenacity-8.5.0 typing-inspect-0.9.0 youtube-search-2.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Embeddings\n",
        "To match the Falcon embedding dimensions, we will have to recreate the embeddings and upload them back to our Neo4j DB. The MPNET has the embedding size we want, and is also trained with a training objective of sentence similarity embedding/matching, which suits our needs here.\n",
        "\n",
        "We first generate the embeddings by taking the movie-plots from Neo4j, then downloading what we get as a CSV file. Because this is a demo project, we will keep it to the first 100 movies."
      ],
      "metadata": {
        "id": "vA_47m-X_OPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "# from openai import OpenAI\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "from langchain import HuggingFaceHub\n",
        "\n",
        "# OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"hf_...\"\n",
        "\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "# model_kwargs = {'device': 'cpu'}\n",
        "# encode_kwargs = {'normalize_embeddings': False}\n",
        "hf = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    # model_kwargs=model_kwargs,\n",
        "    # encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "def get_movie_plots(limit=None):\n",
        "\n",
        "    driver = GraphDatabase.driver(\n",
        "        \"bolt://44.220.93.128:7687\",\n",
        "  auth=basic_auth(\"neo4j\", \"mechanisms-facility-nose\"))\n",
        "\n",
        "\n",
        "    driver.verify_connectivity()\n",
        "\n",
        "    query = \"\"\"MATCH (m:Movie) WHERE m.plot IS NOT NULL\n",
        "    RETURN m.movieId AS movieId, m.title AS title, m.plot AS plot\"\"\"\n",
        "\n",
        "    if limit is not None:\n",
        "        query += f' LIMIT {limit}'\n",
        "\n",
        "    movies, summary, keys = driver.execute_query(\n",
        "        query\n",
        "    )\n",
        "\n",
        "    driver.close()\n",
        "\n",
        "    return movies\n",
        "\n",
        "def generate_embeddings(file_name, limit=None):\n",
        "\n",
        "    csvfile_out = open(file_name, 'w', encoding='utf8', newline='')\n",
        "    fieldnames = ['movieId','embedding']\n",
        "    output_plot = csv.DictWriter(csvfile_out, fieldnames=fieldnames)\n",
        "    output_plot.writeheader()\n",
        "\n",
        "    movies = get_movie_plots(limit=limit)\n",
        "\n",
        "    print(len(movies))\n",
        "\n",
        "    for movie in movies[:100]:\n",
        "        print(movie['title'])\n",
        "\n",
        "        plot = f\"{movie['title']}: {movie['plot']}\"\n",
        "        response = hf.embed_query(\n",
        "            plot,\n",
        "            # model='all-mpnet-base-v2'\n",
        "        )\n",
        "\n",
        "        output_plot.writerow({\n",
        "            'movieId': movie['movieId'],\n",
        "            'embedding': response\n",
        "        })\n",
        "\n",
        "    csvfile_out.close()\n",
        "\n",
        "# generate_embeddings('.\\data\\\\movie-plot-embeddings.csv',limit=1)\n",
        "generate_embeddings('movie-plot-embeddings.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QMqAQvbo95AZ",
        "outputId": "1a43a55b-d454-4c10-c99f-41b3313f4ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9083\n",
            "Toy Story\n",
            "Jumanji\n",
            "Grumpier Old Men\n",
            "Waiting to Exhale\n",
            "Father of the Bride Part II\n",
            "Heat\n",
            "Sabrina\n",
            "Tom and Huck\n",
            "Sudden Death\n",
            "GoldenEye\n",
            "American President, The\n",
            "Dracula: Dead and Loving It\n",
            "Balto\n",
            "Nixon\n",
            "Cutthroat Island\n",
            "Casino\n",
            "Sense and Sensibility\n",
            "Four Rooms\n",
            "Ace Ventura: When Nature Calls\n",
            "Money Train\n",
            "Get Shorty\n",
            "Copycat\n",
            "Assassins\n",
            "Powder\n",
            "Leaving Las Vegas\n",
            "Othello\n",
            "Now and Then\n",
            "Persuasion\n",
            "City of Lost Children, The (Cité des enfants perdus, La)\n",
            "Shanghai Triad (Yao a yao yao dao waipo qiao)\n",
            "Dangerous Minds\n",
            "Twelve Monkeys (a.k.a. 12 Monkeys)\n",
            "Babe\n",
            "Carrington\n",
            "Dead Man Walking\n",
            "Across the Sea of Time\n",
            "It Takes Two\n",
            "Clueless\n",
            "Cry, the Beloved Country\n",
            "Richard III\n",
            "Dead Presidents\n",
            "Restoration\n",
            "Mortal Kombat\n",
            "To Die For\n",
            "How to Make an American Quilt\n",
            "Seven (a.k.a. Se7en)\n",
            "Pocahontas\n",
            "When Night Is Falling\n",
            "Usual Suspects, The\n",
            "Mighty Aphrodite\n",
            "Lamerica\n",
            "Big Green, The\n",
            "Georgia\n",
            "Home for the Holidays\n",
            "Postman, The (Postino, Il)\n",
            "Confessional, The (Confessionnal, Le)\n",
            "Indian in the Cupboard, The\n",
            "Eye for an Eye\n",
            "Mr. Holland's Opus\n",
            "Don't Be a Menace to South Central While Drinking Your Juice in the Hood\n",
            "Two if by Sea\n",
            "Bio-Dome\n",
            "Lawnmower Man 2: Beyond Cyberspace\n",
            "French Twist (Gazon maudit)\n",
            "Friday\n",
            "From Dusk Till Dawn\n",
            "Fair Game\n",
            "Kicking and Screaming\n",
            "Misérables, Les\n",
            "Bed of Roses\n",
            "Screamers\n",
            "Nico Icon\n",
            "Crossing Guard, The\n",
            "Juror, The\n",
            "White Balloon, The (Badkonake sefid)\n",
            "Things to Do in Denver When You're Dead\n",
            "Antonia's Line (Antonia)\n",
            "Once Upon a Time... When We Were Colored\n",
            "Last Summer in the Hamptons\n",
            "Angels and Insects\n",
            "White Squall\n",
            "Dunston Checks In\n",
            "Black Sheep\n",
            "Nick of Time\n",
            "Mary Reilly\n",
            "Vampire in Brooklyn\n",
            "Beautiful Girls\n",
            "Broken Arrow\n",
            "In the Bleak Midwinter\n",
            "Hate (Haine, La)\n",
            "Shopping\n",
            "Heidi Fleiss: Hollywood Madam\n",
            "City Hall\n",
            "Bottle Rocket\n",
            "Mr. Wrong\n",
            "Unforgettable\n",
            "Happy Gilmore\n",
            "Bridges of Madison County, The\n",
            "Muppet Treasure Island\n",
            "Catwalk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we are working on the Sandbox, the config will not allow us to import a local file to our Neo4j DB (such importing is disabled under the security config parameters). If you are creating your own CSV, I recommend you upload it to a website for such purposes (GDrive, GitHub, etc.) and keep that URL ready. If you are pushing it to GitHub like I did, make sure you copy the link to the raw version.\n",
        "\n"
      ],
      "metadata": {
        "id": "2UDGcIJhBvln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cypher with vector semantic search\n",
        "\n",
        "Next, we will upload our embeddings back to our Neo4j DB and create an index on it. I am adapting the same queries from the tutorial, reproduced here for ready reference:\n",
        "\n",
        "1. MATCH (m:Movie {title: \"Toy Story\"})\n",
        "RETURN m.title AS title, m.plot AS plot\n",
        "\n",
        " #Sanity check\n",
        "\n",
        "2. LOAD CSV WITH HEADERS\n",
        "FROM 'https://data.neo4j.com/llm-fundamentals/openai-embeddings.csv'\n",
        "AS row\n",
        "MATCH (m:Movie {movieId: row.movieId})\n",
        "CALL db.create.setNodeVectorProperty(m, 'plotEmbedding', apoc.convert.fromJsonList(row.embedding))\n",
        "RETURN count(*)\n",
        "\n",
        "  #Import CSV and make a new field for the relevant existing nodes\n",
        "\n",
        "3. MATCH (m:Movie {title: \"Toy Story\"})\n",
        "RETURN m.title AS title, m.plot AS plot, m.plotEmbedding\n",
        "\n",
        "  #Updated DB Sanity check\n",
        "\n",
        "4. CREATE VECTOR INDEX moviePlots IF NOT EXISTS\n",
        "FOR (m:Movie)\n",
        "ON m.plotEmbedding\n",
        "OPTIONS {indexConfig: {\n",
        " `vector.dimensions`: 1536,\n",
        " `vector.similarity_function`: 'cosine'\n",
        "}}\n",
        "\n",
        "  #Index creation (no output)\n",
        "\n",
        "5. SHOW INDEXES  YIELD id, name, type, state, populationPercent WHERE type = \"VECTOR\"\n",
        "\n",
        "  #Sanity check (population% should be 100)\n",
        "\n",
        "6. MATCH (m:Movie {title: 'Toy Story'})\n",
        "CALL db.index.vector.queryNodes('moviePlots', 6, m.plotEmbedding)\n",
        "YIELD node, score\n",
        "RETURN node.title AS title, node.plot AS plot, score\n",
        "\n",
        "  #Testing semantic vector search\n",
        "\n",
        "PS: The queries above are as-is from your guide for your reference, they are tweaked in the actual code below. You may also tweak accordingly."
      ],
      "metadata": {
        "id": "tA6A5s9YGlzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip3 install neo4j-driver - not needed\n",
        "# python3 example.py\n",
        "\n",
        "from neo4j import GraphDatabase, basic_auth\n",
        "\n",
        "driver = GraphDatabase.driver(\n",
        "    \"bolt://44.220.93.128:7687\",\n",
        "  auth=basic_auth(\"neo4j\", \"mechanisms-facility-nose\"))\n",
        "\n",
        "\n",
        "driver.verify_connectivity()\n",
        "\n",
        "queries = [\"\"\"MATCH (m:Movie {title: \"Toy Story\"}) RETURN m.title AS title, m.plot AS plot\"\"\",\"\"\"LOAD CSV WITH HEADERS FROM\n",
        "'https://raw.githubusercontent.com/FauzanFarooqui/hello-world/refs/heads/main/movie-plot-embeddings.csv' AS row MATCH (m:Movie {movieId: row.movieId})\n",
        "CALL db.create.setNodeVectorProperty(m, 'plotEmbedding', apoc.convert.fromJsonList(row.embedding)) RETURN count(*)\"\"\", \"\"\"MATCH (m:Movie {title: \"Toy Story\"})\n",
        "RETURN m.title AS title, m.plot AS plot, m.plotEmbedding\"\"\", \"\"\"DROP INDEX moviePlots\"\"\" , \"\"\"CREATE VECTOR INDEX moviePlots IF NOT EXISTS FOR (m:Movie) ON m.plotEmbedding\n",
        "OPTIONS {indexConfig: { `vector.dimensions`: 768, `vector.similarity_function`: 'cosine' }}\"\"\", \"\"\"SHOW INDEXES YIELD id, name, type, state, populationPercent WHERE type = 'VECTOR' \"\"\",\n",
        "\"\"\"MATCH (m:Movie {title: 'Toy Story'})\n",
        "\n",
        "CALL db.index.vector.queryNodes('moviePlots', 6, m.plotEmbedding) YIELD node, score\n",
        "\n",
        "RETURN node.title AS title, node.plot AS plot, score \"\"\" ]\n",
        "\n",
        "# if limit is not None:\n",
        "#   query += f' LIMIT {limit}'\n",
        "for query in queries:\n",
        "  movies, summary, keys = driver.execute_query(\n",
        "    query\n",
        "  )\n",
        "  print (\"Movies\", movies, \"\\nSum\", summary, \"\\nKey\", keys, \"\\n\")\n",
        "\n",
        "driver.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nZ4YBV-sKW8R",
        "outputId": "266413d6-fa19-4269-bd97-a78ef947e71a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movies [<Record title='Toy Story' plot=\"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.\">] \n",
            "Sum <neo4j._work.summary.ResultSummary object at 0x78262e736e30> \n",
            "Key ['title', 'plot'] \n",
            "\n",
            "Movies [<Record count(*)=100>] \n",
            "Sum <neo4j._work.summary.ResultSummary object at 0x78262e7d0160> \n",
            "Key ['count(*)'] \n",
            "\n",
            "Movies [<Record title='Toy Story' plot=\"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.\" m.plotEmbedding=[0.05740255489945412, 0.043752674013376236, -0.005099424161016941, 0.0011854032054543495, -0.008661516942083836, 0.02697652392089367, 0.007698857691138983, -0.008475186303257942, -0.02351144514977932, 0.010201675817370415, 0.01100873202085495, -0.09389089792966843, 0.016855904832482338, 0.049800675362348557, -0.0035002632066607475, -0.019216863438487053, 0.021932777017354965, -0.022039487957954407, 0.037455376237630844, -0.016466926783323288, 0.009910630993545055, -0.021207541227340698, -0.0014818781055510044, 0.01597960852086544, -0.06064664572477341, 0.01066102460026741, 0.046808842569589615, 0.021947866305708885, -0.0022192453034222126, -0.08734720200300217, 0.01936238445341587, -0.04288170114159584, 0.01642598770558834, 0.011890889145433903, 1.3644599903273047e-06, -0.022096607834100723, -0.0023445275146514177, 0.015418381430208683, 0.057465795427560806, 0.03318260237574577, 0.03565356135368347, 0.016898544505238533, 0.0028005109634250402, 0.004818705841898918, 0.054032452404499054, 0.020083235576748848, 0.03293533995747566, 0.07169497758150101, -0.00024066564219538122, -0.014662346802651882, -0.005144423805177212, -0.012286433018743992, -0.06458424776792526, -0.012226799502968788, 0.08043109625577927, 0.031092284247279167, -0.017176251858472824, 0.06696072965860367, 0.07663403451442719, -0.016425302252173424, -0.09470214694738388, -0.03436312824487686, -0.017809582874178886, 0.014090740121901035, 0.01897294446825981, 0.005155964754521847, -0.038705870509147644, 0.01785416528582573, -0.04194139316678047, 0.010253126733005047, -0.0017923451960086823, 0.004441489931195974, 0.01694939099252224, 0.0405522957444191, 0.0034211636520922184, -0.043856430798769, -0.05497456341981888, 0.11595325917005539, -0.002418513409793377, -0.016227634623646736, -0.03593851998448372, -0.003986891359090805, -0.030942924320697784, 0.006335734389722347, 0.06781411170959473, -0.03271803259849548, 0.0024971438106149435, 0.0011922733392566442, -0.03489553555846214, -0.043599966913461685, 0.009935564361512661, -0.027082575485110283, 0.05172514170408249, -0.018333954736590385, 0.023114830255508423, -0.0019184231059625745, -0.04734225571155548, 0.047317665070295334, 0.007693815510720015, -0.08737342059612274, -0.04127994179725647, 0.007874432019889355, 0.046241044998168945, 0.05659598484635353, 0.004014438949525356, 0.04947594553232193, 0.047744765877723694, -0.021251758560538292, 0.031113410368561745, 0.04058021679520607, -0.021442880854010582, 0.009491851553320885, -0.006285002455115318, 0.04370252415537834, 0.08766157180070877, -0.0334395132958889, 0.06421005725860596, 0.0012710138689726591, -0.003451672615483403, 0.01182325929403305, -0.019364764913916588, 0.026801342144608498, 0.008518137037754059, 0.0401763953268528, -0.03376772999763489, 0.00024105788907036185, -0.06372218579053879, 0.03622063994407654, 0.03527992591261864, -0.019807158038020134, -0.02421187236905098, -0.027068866416811943, -0.0037769125774502754, 0.005631237756460905, 0.006360165774822235, -0.013718020170927048, 0.01630113087594509, 0.04139597341418266, -0.028264008462429047, 0.024286890402436256, 0.01076231524348259, 0.0035984644200652838, -0.03824113681912422, -0.018743937835097313, 0.037244491279125214, -0.0164683498442173, 0.013592730276286602, -0.04125683382153511, 0.0279097780585289, -0.05851886793971062, -0.013438009656965733, -0.0005807603010907769, 0.06701167672872543, -0.005091778934001923, -0.0007791232783347368, 0.021145617589354515, -0.04096243157982826, -0.01708069257438183, -0.006408256012946367, -0.016919154673814774, -0.0022125716786831617, 0.03266024962067604, -0.03250046819448471, -0.04382982477545738, -0.05201805382966995, -0.015532191842794418, -0.04860462620854378, -0.01755698397755623, 0.054742731153964996, 0.06077253073453903, -0.06537958979606628, -0.009792009368538857, -0.04950477555394173, 0.027227822691202164, 0.02229144051671028, 0.02278400957584381, -0.023930473253130913, -0.006034160032868385, -0.0466768704354763, 0.06414462625980377, -0.05020839720964432, -0.0033888069447129965, -0.008083737455308437, 0.01879497431218624, -0.0011322213103994727, -0.06150417402386665, -0.04610968381166458, 0.016116930171847343, -0.012198477983474731, 0.040478870272636414, 0.0724107101559639, 0.011716756038367748, 0.05336454138159752, -0.026735350489616394, -0.009498922154307365, -0.011516226455569267, -0.0016950452700257301, 0.0060049002058804035, 0.010326522402465343, -0.006693643052130938, 0.0015772805782034993, 0.0754750594496727, 0.014384911395609379, -0.015917498618364334, 0.006821562070399523, -0.0035597579553723335, -0.01674170233309269, -0.03581693768501282, 0.03718837350606918, -0.01949327625334263, -0.03307349234819412, 0.015074651688337326, 0.013598551973700523, 0.023427458480000496, -0.014077547937631607, -0.007808193098753691, 0.052642349153757095, 0.048757296055555344, -0.03715908154845238, 0.012427778914570808, -0.027643321081995964, 0.029083695262670517, 0.04447060078382492, 0.040606919676065445, -0.004567554220557213, 0.009794792160391808, 0.014122036285698414, 0.011024502106010914, 0.014471570029854774, 0.01050356961786747, 0.012144306674599648, -0.0006211489671841264, 0.04035812243819237, 0.035475101321935654, 0.044956404715776443, 0.02227468229830265, 0.019705040380358696, -0.014123693108558655, 0.0031709487084299326, -0.10795809328556061, -0.050776515156030655, 0.044353581964969635, 0.0015051603550091386, 0.04320487380027771, 0.034659482538700104, -0.05243201553821564, -0.0023989202454686165, 0.012030869722366333, 0.021936148405075073, 0.006127963773906231, -0.0157165564596653, -0.017579684033989906, -0.03223748132586479, -0.008577072992920876, -0.003663279116153717, -0.022052979096770287, 0.010162623599171638, 0.034342873841524124, 0.019482430070638657, 0.011395127512514591, 0.07333248853683472, -0.07294310629367828, 0.0347551666200161, 0.010431733913719654, -0.05347201228141785, 0.016648689284920692, 0.017201632261276245, 0.029574358835816383, -0.04516051337122917, 0.048023637384176254, -0.0483129620552063, 0.026428621262311935, -0.010945803485810757, -0.012234401889145374, -0.02187744900584221, -0.006468803156167269, -0.007213169708848, 0.013168837875127792, -0.022483155131340027, 0.0406220518052578, 0.022327018901705742, -0.007691992446780205, -0.009365136735141277, 0.00043116582673974335, -0.007011379115283489, 0.022621063515543938, 0.02293592318892479, 0.020440971478819847, -0.012820093892514706, -0.020942864939570427, -0.003866492072120309, 0.0009614325826987624, 0.0037849522195756435, 0.04179087281227112, 0.032519981265068054, 0.0012732008472085, -0.010634406469762325, 0.0006269363220781088, -0.01451668981462717, -0.03836875408887863, 0.05262113735079765, 0.0017825835384428501, -0.006411242298781872, -0.04874039068818092, 0.07311803102493286, -0.005674805957823992, 0.05780595913529396, -0.0023266272619366646, -0.04962713643908501, 0.015825025737285614, -0.008072280324995518, 0.01405948307365179, -0.020441900938749313, 0.0074795265682041645, 0.017562558874487877, -0.03107086941599846, 0.006146965082734823, -0.01737547479569912, -0.03755350038409233, 0.04485334828495979, -0.002646523527801037, 0.04693398252129555, 0.021160298958420753, -0.05070419982075691, -0.00028822003514505923, 0.03860320895910263, 0.035169217735528946, 0.0020774221047759056, 0.04197040945291519, -0.001620420953258872, 0.0051808743737638, 0.010576330125331879, 0.002921672072261572, -0.05221028998494148, 0.09197699278593063, -0.018161362037062645, -0.012885878793895245, -0.06846120953559875, -0.03723795339465141, 0.028126154094934464, 0.022721577435731888, 0.038730647414922714, -0.022771507501602173, -0.07705606520175934, 0.042108096182346344, -0.010064407251775265, 0.01049266941845417, -0.05867573618888855, -0.010510786436498165, 0.015213876031339169, -0.030993862077593803, 0.040822289884090424, -0.005865524522960186, 0.010386238805949688, 0.0047232783399522305, -0.021681377664208412, 0.04939159378409386, 0.011382115073502064, -0.03777439519762993, 0.016161223873496056, -0.03760369122028351, 0.003118660533800721, 0.03363387659192085, -0.023611415177583694, -0.023929350078105927, 0.016928676515817642, -0.07736355066299438, 0.042181383818387985, 0.04030373692512512, -0.019951391965150833, -0.01681598275899887, -0.012041102163493633, -0.014178233221173286, -0.04863365739583969, -0.011876650154590607, 0.07388842105865479, -0.007868361659348011, 0.033303238451480865, 0.029306117445230484, -0.03266526386141777, 0.002199106849730015, -0.005464066751301289, -0.006788990460336208, -0.0028307526372373104, -0.06718841195106506, -0.008571360260248184, -0.023174263536930084, -0.006360629107803106, -0.014133093878626823, 0.0003257074858993292, -0.018611092120409012, -0.012414807453751564, -0.08103200048208237, 0.0384947769343853, -0.03973856568336487, 0.044825222343206406, -0.10784009099006653, 0.05048419535160065, -0.06718890368938446, 0.005968485958874226, -0.030238492414355278, 0.11345577239990234, 0.0006292709149420261, 0.11043843626976013, 0.033217959105968475, 0.023540830239653587, 0.02388232946395874, -0.022573987022042274, -0.035992637276649475, 0.07153422385454178, -0.06573796272277832, 0.04085978865623474, -0.04707907885313034, -0.016876183450222015, -0.07824498414993286, -0.028643997386097908, -0.017287733033299446, -0.02283884584903717, -0.026815980672836304, 0.06524839997291565, 0.026188772171735764, 0.027078017592430115, 0.04589442163705826, -0.011805328540503979, 0.02731121890246868, -0.02260005474090576, 0.021182909607887268, -0.022398734465241432, 0.06497003138065338, -0.0005235638236626983, 0.02571241743862629, 0.005915474146604538, -0.02788088284432888, -0.01051346305757761, 0.008378889411687851, 0.017377836629748344, 0.02721560373902321, -0.001500844955444336, -0.018967296928167343, -0.01801171526312828, 0.02930404059588909, 0.007662374526262283, -0.014164775609970093, 0.009105635806918144, -0.049743205308914185, -0.1296100914478302, 0.020960470661520958, -0.0595087893307209, 0.03508570417761803, 0.07741076499223709, -0.03310255706310272, -0.004048297181725502, 0.025784416124224663, -0.0024822389241307974, -0.015438036993145943, -0.03193628042936325, -0.030318070203065872, 0.010801248252391815, -0.03734699264168739, 0.0014984824229031801, -0.011528177186846733, 0.0004159804666414857, -0.014780218712985516, 0.062428075820207596, 0.029050612822175026, 0.004871548153460026, 0.02135845087468624, -0.020238086581230164, 0.03638239949941635, -0.007392536383122206, 0.012242074124515057, -0.04359631985425949, 0.0078060138039290905, -0.025066517293453217, -0.062245190143585205, -0.08061811327934265, 0.018105635419487953, -0.044110409915447235, 0.013010483235120773, -0.0008489630417898297, -0.008022966794669628, 0.009991675615310669, 0.017076382413506508, 0.033157747238874435, -0.01317302230745554, -0.016202179715037346, -0.01546927448362112, 0.011888687498867512, -0.07499604672193527, 0.0067634619772434235, -0.020994625985622406, 0.0495019294321537, -0.025133885443210602, 0.0008750855922698975, -0.019575392827391624, 0.04485035687685013, 0.03159593418240547, -0.06038829684257507, -0.014544438570737839, -0.07200425863265991, -0.02960469387471676, 0.02153586409986019, -0.02111627720296383, 0.04063147306442261, -0.017918499186635017, 0.02012620121240616, -0.03753861039876938, -0.011920991353690624, -0.01044340431690216, -0.010762657970190048, -0.015716122463345528, 0.03656600043177605, 0.044320810586214066, -0.027367064729332924, -0.005035304930061102, 0.002652859315276146, -0.05771712586283684, -0.07611507177352905, -0.026327798143029213, -0.018114015460014343, 0.006796456873416901, -0.02880239486694336, -0.07632354646921158, -0.016252683475613594, -0.04687313735485077, 0.018041439354419708, 0.025455323979258537, 0.07092492282390594, -0.0016597085632383823, 0.016421861946582794, -0.02564024180173874, 0.03619631752371788, -0.008430710062384605, 0.029010359197854996, -0.011562427505850792, 0.038434118032455444, 0.039863407611846924, -0.025248117744922638, 0.018671995028853416, 0.04668114706873894, -0.0021626208908855915, 0.021240130066871643, -0.08724882453680038, -0.01685822568833828, 0.036549415439367294, -0.005575403105467558, 0.04120507091283798, 0.003332105465233326, 0.006790071725845337, -0.017849773168563843, -0.03824866563081741, -0.044831302016973495, 0.06367706507444382, 0.004336976446211338, -0.013876369222998619, -5.089988252028417e-33, -0.013242767192423344, 0.007424378301948309, -0.07179670035839081, -0.025782598182559013, -0.007463812828063965, -0.040738437324762344, -0.014471478760242462, 0.018465377390384674, 0.009657231159508228, 0.014565573073923588, 0.008231624960899353, -0.021060872822999954, 0.006921661086380482, -0.016097664833068848, 0.02705884352326393, 0.03291875496506691, 0.02737843059003353, 0.030466565862298012, 0.052117958664894104, -0.04116414487361908, -0.005889945197850466, 0.04190681874752045, 0.019377898424863815, -0.029125312343239784, -0.03277020528912544, 0.007496076636016369, -0.031162982806563377, 0.005767599679529667, 0.07620836794376373, 0.018217721953988075, 0.005914903245866299, -0.04140531271696091, -0.014597158879041672, -0.014004334807395935, 0.003354006679728627, 0.0019802949391305447, -0.02504531666636467, 0.0337083674967289, -0.03618427366018295, -0.058734193444252014, 0.03647981584072113, -0.009810109622776508, 0.01240119431167841, -0.06024735048413277, 0.03743418678641319, -0.0339830219745636, 0.009345311671495438, 0.012659602798521519, 0.013756969012320042, 0.05909423530101776, -0.03232245519757271, -0.005207982379943132, -0.030009543523192406, -0.05572512000799179, 0.06694237142801285, 0.09026546031236649, -0.0087766507640481, 0.02450237050652504, 0.0312887541949749, 0.06294061243534088, -0.010257747955620289, 0.046859052032232285, -0.03964565694332123, -0.006862678565084934, 0.05162854492664337, 0.09186986088752747, 0.021727953106164932, -0.014571676962077618, -0.05040944740176201, 0.02947308123111725, -0.04768151789903641, -0.035014137625694275, 0.024301784113049507, -0.04740707948803902, 0.008381659165024757, -0.019144894555211067, -0.08869937807321548, 0.01572919823229313, 0.05130846053361893, 0.0422029122710228, -0.009332215413451195, 0.037207502871751785, 0.0006606308743357658, 0.022546332329511642, 0.015850551426410675, 0.006441487930715084, 0.008523650467395782, -0.06780098378658295, -0.03765815123915672, -0.003952515311539173, -0.05900998413562775, 0.03613370284438133, -0.0018292292952537537, 0.000653206545393914, -0.030175454914569855, -0.035453662276268005, 0.006618948187679052, -0.011736059561371803, 0.03986341878771782, -0.007996968924999237, 0.0491250641644001, -0.015954436734318733, 0.034765638411045074, 0.006700918078422546, 0.05080993473529816, 0.004608968738466501, -0.037740424275398254, -0.018691672012209892, -0.001778238802216947, -0.025493547320365906, 0.049225904047489166, -0.05462763458490372, -0.03568766266107559, -0.03573840484023094, -0.043987978249788284, -0.015582089312374592, -0.006260766182094812, 0.056925687938928604, -0.03948948532342911, 0.014423301443457603, -0.030765140429139137, -0.0320093035697937, -0.07086131721735, 0.03200994059443474, -0.043859079480171204, -0.006239360198378563, -0.03970831260085106, -0.026582228019833565, 0.10730056464672089, -0.001862800563685596, -8.965651068137959e-05, -0.08810129016637802, 2.2735578397714562e-07, -0.07414025068283081, 0.006404956337064505, 0.04076630249619484, 0.015459817834198475, -0.011685026809573174, 0.03317135572433472, -0.04890823736786842, 0.0266705434769392, 0.0305724386125803, -0.05888573080301285, -0.013462860137224197, -0.022120246663689613, -0.027734968811273575, -0.013364708051085472, -0.012592899613082409, -0.0181704331189394, 0.043630097061395645, -0.055280525237321854, 0.03107088804244995, -0.005241258069872856, 0.06228035315871239, 0.006928686518222094, -0.03917313739657402, 0.01753026247024536, -0.005316882859915495, -0.017656361684203148, 0.0007883030921220779, 0.030872564762830734, -0.020012225955724716, -0.015477924607694149, -0.08143666386604309, 0.012631947174668312, -0.03770378232002258, -0.03345785290002823, 0.004920762963593006, -0.03814280405640602, 0.044099658727645874, 0.062368810176849365, -0.036563873291015625, 0.008240947499871254, 0.01910221204161644, 0.08416782319545746, -0.05085916072130203, 0.03478590399026871, 0.016933269798755646, -0.023612281307578087, -0.007795270066708326, 0.009274723008275032, 0.03900768980383873, 0.03358942270278931, 0.05666107311844826, -0.021902216598391533, -0.0018842372810468078, 0.009949523955583572, -0.03428923338651657, 0.011044550687074661, 0.008495968766510487, -0.02767036482691765, -0.014100714586675167, 0.012093107216060162, -0.07357537746429443, 0.06696422398090363, 0.06482818722724915, 0.00878287386149168, -0.10764279216527939, 0.011181126348674297, 0.001146875787526369, 1.6438157771703246e-34, 0.021383050829172134, -0.03518810495734215, 0.03276772424578667, -0.025069382041692734, 0.04840628430247307, 0.017393607646226883, 0.08726828545331955, 0.012049918994307518, 0.008018195629119873, 0.04956989362835884, -0.038305047899484634]>] \n",
            "Sum <neo4j._work.summary.ResultSummary object at 0x78262e7d0b80> \n",
            "Key ['title', 'plot', 'm.plotEmbedding'] \n",
            "\n",
            "Movies [] \n",
            "Sum <neo4j._work.summary.ResultSummary object at 0x78262e7d0190> \n",
            "Key [] \n",
            "\n",
            "Movies [] \n",
            "Sum <neo4j._work.summary.ResultSummary object at 0x78262e7d1090> \n",
            "Key [] \n",
            "\n",
            "Movies [<Record id=3 name='moviePlots' type='VECTOR' state='POPULATING' populationPercent=0.0>] \n",
            "Sum <neo4j._work.summary.ResultSummary object at 0x78262e7d2980> \n",
            "Key ['id', 'name', 'type', 'state', 'populationPercent'] \n",
            "\n",
            "Movies [<Record title='Toy Story' plot=\"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.\" score=1.0>, <Record title='Powder' plot='A young bald albino boy with unique powers shakes up the rural community he lives in.' score=0.7194911241531372>, <Record title='Muppet Treasure Island' plot=\"The Muppets' twist on the classic tale.\" score=0.7084532380104065>, <Record title='Mr. Wrong' plot='A single and lonely woman finds the seemingly perfect man to date, but soon regrets it when his deranged and possessive other personality emerges and worst still, she cannot convince anyone else of his Jekyll/Hyde true nature.' score=0.690491795539856>, <Record title='Bottle Rocket' plot='Focusing on a trio of friends and their elaborate plan to pull off a simple robbery and go on the run.' score=0.6892232894897461>, <Record title='Happy Gilmore' plot=\"A rejected hockey player puts his skills to the golf course to save his grandmother's house.\" score=0.6876521110534668>] \n",
            "Sum <neo4j._work.summary.ResultSummary object at 0x78262e734460> \n",
            "Key ['title', 'plot', 'score'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain\n"
      ],
      "metadata": {
        "id": "rN4Q18Q4lVIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below cells are the guide taken from the official course, that requires access to the OpenAI API. The last sub-section gives the full code for the entire example you would like to see for the Neo4j+LLM+RAG example as in the course. However, as I don't have access to OpenAPI, I show a \"MVP\" working RAG example with Falcon in the last cell of this notebook (without a memory-chat-like interface, just independent querying."
      ],
      "metadata": {
        "id": "HlNeSY3ZENNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting\n",
        "\n",
        "The first step to talking to a LLM is to see how you can pass a prompt with an input variable."
      ],
      "metadata": {
        "id": "ihVG4Ecgldhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI(\n",
        "    openai_api_key=\"sk-...\",\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "response = llm.invoke(\"What is Neo4j?\")\n",
        "\n",
        "print(response)\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = PromptTemplate(template=\"\"\"\n",
        "You are a cockney fruit and vegetable seller.\n",
        "Your role is to assist your customer with their fruit and vegetable needs.\n",
        "Respond using cockney rhyming slang.\n",
        "\n",
        "Tell me about the following fruit: {fruit}\n",
        "\"\"\", input_variables=[\"fruit\"])\n",
        "\n",
        "response = llm.invoke(template.format(fruit=\"apple\"))\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "6tUdS4s-i7Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chaining\n",
        "\n",
        "The next step is to see how you can \"chain\" various components up together and invoke it in one go a very simple way."
      ],
      "metadata": {
        "id": "t2d972H-lmIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = OpenAI(openai_api_key=\"sk-...\")\n",
        "\n",
        "template = PromptTemplate.from_template(\"\"\"\n",
        "You are a cockney fruit and vegetable seller.\n",
        "Your role is to assist your customer with their fruit and vegetable needs.\n",
        "Respond using cockney rhyming slang.\n",
        "\n",
        "Output JSON as {{\"description\": \"your response here\"}}\n",
        "\n",
        "Tell me about the following fruit: {fruit}\n",
        "\"\"\")\n",
        "\n",
        "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
        "\n",
        "llm_chain = template | llm | SimpleJsonOutputParser() # Default: from langchain.schema import StrOutputParser -> StrOutputParser()\n",
        "\n",
        "response = llm_chain.invoke({\"fruit\": \"apple\"})\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "96351iwdvLrV",
        "outputId": "c2d29e86-f109-41b9-a56a-e2128e18acb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_openai'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-22565c7507ac>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopenai_api_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sk-...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_openai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat model\n",
        "Querying a model with context."
      ],
      "metadata": {
        "id": "IN2e0kuJlqcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "chat_llm = ChatOpenAI(\n",
        "    openai_api_key=\"sk-...\"\n",
        ")\n",
        "\n",
        "instructions = SystemMessage(content=\"\"\"\n",
        "You are a surfer dude, having a conversation about the surf conditions on the beach.\n",
        "Respond using surfer slang.\n",
        "\"\"\")\n",
        "\n",
        "question = HumanMessage(content=\"What is the weather like?\")\n",
        "\n",
        "response = chat_llm.invoke([\n",
        "    instructions,\n",
        "    question\n",
        "])\n",
        "\n",
        "print(response.content) #AIMessage(content=\"Dude, the weather is totally gnarly! It's sunny with some epic offshore winds. Perfect conditions for shredding some sick waves!\", additional_kwargs={}, example=False)\n",
        "\n",
        "# Above as a chain with context:\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "chat_llm = ChatOpenAI(openai_api_key=\"sk-...\")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a surfer dude, having a conversation about the surf conditions on the beach. Respond using surfer slang.\",\n",
        "        ),\n",
        "        ( \"system\", \"{context}\" ),\n",
        "        ( \"human\", \"{question}\" ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chat_chain = prompt | chat_llm | StrOutputParser()\n",
        "\n",
        "current_weather = \"\"\"\n",
        "    {\n",
        "        \"surf\": [\n",
        "            {\"beach\": \"Fistral\", \"conditions\": \"6ft waves and offshore winds\"},\n",
        "            {\"beach\": \"Polzeath\", \"conditions\": \"Flat and calm\"},\n",
        "            {\"beach\": \"Watergate Bay\", \"conditions\": \"3ft waves and onshore winds\"}\n",
        "        ]\n",
        "    }\"\"\"\n",
        "\n",
        "response = chat_chain.invoke(\n",
        "    {\n",
        "        \"context\": current_weather,\n",
        "        \"question\": \"What is the weather like on Watergate Bay?\",\n",
        "    }\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "dI3AVMpCl35c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memory"
      ],
      "metadata": {
        "id": "0Ojfgat9zy7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a surfer dude, having a conversation about the surf conditions on the beach. Respond using surfer slang.\",\n",
        "        ),\n",
        "        (\"system\", \"{context}\"),\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "\n",
        "memory = ChatMessageHistory()\n",
        "\n",
        "def get_memory(session_id):\n",
        "    return memory\n",
        "\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "chat_chain = prompt | chat_llm | StrOutputParser()\n",
        "\n",
        "chat_with_message_history = RunnableWithMessageHistory(\n",
        "    chat_chain,\n",
        "    get_memory,\n",
        "    input_messages_key=\"question\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")\n",
        "\n",
        "response = chat_with_message_history.invoke(\n",
        "    {\n",
        "        \"context\": current_weather,\n",
        "        \"question\": \"Hi, I am at Watergate Bay. What is the surf like?\"\n",
        "    },\n",
        "    config={\"configurable\": {\"session_id\": \"none\"}}\n",
        ")\n",
        "print(response)\n",
        "\n",
        "response = chat_with_message_history.invoke(\n",
        "    {\n",
        "        \"context\": current_weather,\n",
        "        \"question\": \"Where I am?\"\n",
        "    },\n",
        "    config={\"configurable\": {\"session_id\": \"none\"}}\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "NRQQOwAbz03K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    question = input(\"> \")\n",
        "\n",
        "    response = chat_with_message_history.invoke(\n",
        "        {\n",
        "            \"context\": current_weather,\n",
        "            \"question\": question,\n",
        "\n",
        "        },\n",
        "        config={\n",
        "            \"configurable\": {\"session_id\": \"none\"}\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(response)"
      ],
      "metadata": {
        "id": "WMcz1Ev5HhsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memory storage in Neo4j"
      ],
      "metadata": {
        "id": "uDHHzLiNFlws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.graphs import Neo4jGraph\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=\"bolt://18.233.226.221:7687\",\n",
        "    username=\"neo4j\",\n",
        "    password=\"monitors-terminators-mile\"\n",
        ")\n",
        "\n",
        "result = graph.query(\"\"\"\n",
        "MATCH (m:Movie{title: 'Toy Story'})\n",
        "RETURN m.title, m.plot, m.poster\n",
        "\"\"\")\n",
        "\n",
        "print(result)\n",
        "\n",
        "print(graph.schema) #graph.refresh_schema()\n",
        "\n",
        "from uuid import uuid4\n",
        "\n",
        "SESSION_ID = str(uuid4())\n",
        "print(f\"Session ID: {SESSION_ID}\")\n",
        "\n",
        "from langchain_community.chat_message_histories import Neo4jChatMessageHistory\n",
        "\n",
        "def get_memory(session_id):\n",
        "    return Neo4jChatMessageHistory(session_id=session_id, graph=graph)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA3mFNlnFkT6",
        "outputId": "737a3e3d-f463-4447-c375-119cf6e7b5ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'m.title': 'Toy Story', 'm.plot': \"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.\", 'm.poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg'}]\n",
            "Node properties:\n",
            "Movie {url: STRING, runtime: INTEGER, revenue: INTEGER, budget: INTEGER, plotEmbedding: LIST, imdbRating: FLOAT, released: STRING, countries: LIST, languages: LIST, plot: STRING, imdbVotes: INTEGER, imdbId: STRING, year: INTEGER, poster: STRING, movieId: STRING, tmdbId: STRING, title: STRING}\n",
            "Genre {name: STRING}\n",
            "User {userId: STRING, name: STRING}\n",
            "Actor {url: STRING, bornIn: STRING, bio: STRING, died: DATE, born: DATE, imdbId: STRING, name: STRING, poster: STRING, tmdbId: STRING}\n",
            "Director {url: STRING, bornIn: STRING, bio: STRING, died: DATE, born: DATE, imdbId: STRING, name: STRING, poster: STRING, tmdbId: STRING}\n",
            "Person {url: STRING, bornIn: STRING, bio: STRING, died: DATE, born: DATE, imdbId: STRING, name: STRING, poster: STRING, tmdbId: STRING}\n",
            "Relationship properties:\n",
            "RATED {rating: FLOAT, timestamp: INTEGER}\n",
            "ACTED_IN {role: STRING}\n",
            "DIRECTED {role: STRING}\n",
            "The relationships:\n",
            "(:Movie)-[:IN_GENRE]->(:Genre)\n",
            "(:User)-[:RATED]->(:Movie)\n",
            "(:Actor)-[:ACTED_IN]->(:Movie)\n",
            "(:Actor)-[:DIRECTED]->(:Movie)\n",
            "(:Director)-[:DIRECTED]->(:Movie)\n",
            "(:Director)-[:ACTED_IN]->(:Movie)\n",
            "(:Person)-[:ACTED_IN]->(:Movie)\n",
            "(:Person)-[:DIRECTED]->(:Movie)\n",
            "Session ID: fd3c3496-4a83-46c6-8b01-7bfcafafb86e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming previous relevant sub-sections have run, or copy them here again if u like\n",
        "while True:\n",
        "    question = input(\"> \")\n",
        "\n",
        "    response = chat_with_message_history.invoke(\n",
        "        {\n",
        "            \"context\": current_weather,\n",
        "            \"question\": question,\n",
        "\n",
        "        },\n",
        "        config={\n",
        "            \"configurable\": {\"session_id\": \"none\"}\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(response)"
      ],
      "metadata": {
        "id": "QVQ_TPQxHteN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents\n",
        "\n",
        "Follow along with the course."
      ],
      "metadata": {
        "id": "dImrap2jL8b4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain.tools import Tool\n",
        "from langchain import hub\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain_community.tools import YouTubeSearchTool\n",
        "from langchain_community.chat_message_histories import Neo4jChatMessageHistory\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from uuid import uuid4\n",
        "\n",
        "SESSION_ID = str(uuid4())\n",
        "print(f\"Session ID: {SESSION_ID}\")\n",
        "\n",
        "llm = ChatOpenAI(openai_api_key=\"sk-...\")\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=\"bolt://54.159.230.252:7687\",\n",
        "    username=\"neo4j\",\n",
        "    password=\"boom-expansion-sterilizer\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a movie expert. You find movies from a genre or plot.\",\n",
        "        ),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "movie_chat = prompt | llm | StrOutputParser()\n",
        "\n",
        "youtube = YouTubeSearchTool()\n",
        "\n",
        "def get_memory(session_id):\n",
        "    return Neo4jChatMessageHistory(session_id=session_id, graph=graph)\n",
        "\n",
        "def call_trailer_search(input):\n",
        "    input = input.replace(\",\", \" \")\n",
        "    return youtube.run(input)\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        name=\"Movie Chat\",\n",
        "        description=\"For when you need to chat about movies. The question will be a string. Return a string.\",\n",
        "        func=movie_chat.invoke,\n",
        "    ),\n",
        "    Tool.from_function(\n",
        "        name=\"Movie Trailer Search\",\n",
        "        description=\"Use when needing to find a movie trailer. The question will include the word trailer. Return a link to a YouTube video.\",\n",
        "        func=call_trailer_search,\n",
        "    ),\n",
        "]\n",
        "\n",
        "agent_prompt = hub.pull(\"hwchase17/react-chat\") #https://smith.langchain.com/hub/hwchase17/react-chat?organizationId=d9a804f5-9c91-5073-8980-3d7112f1cbd3\n",
        "agent = create_react_agent(llm, tools, agent_prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools)  # max_iterations=3,    verbose=True,    handle_parse_errors=True\n",
        "\n",
        "chat_agent = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    get_memory,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")\n",
        "\n",
        "while True:\n",
        "    q = input(\"> \")\n",
        "\n",
        "    response = chat_agent.invoke(\n",
        "        {\n",
        "            \"input\": q\n",
        "        },\n",
        "        {\"configurable\": {\"session_id\": SESSION_ID}},\n",
        "    )\n",
        "\n",
        "    print(response[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "Z1QFxWazkWSH",
        "outputId": "c0fd9844-07b2-4872-bf8b-43dd89c48ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session ID: 8112f867-6a08-4b9e-9005-439eb6bee4b6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> A science-fiction movie about climate change.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownRelationshipTypeWarning} {category: UNRECOGNIZED} {title: The provided relationship type is not in the database.} {description: One of the relationship types in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing relationship type is: LAST_MESSAGE)} {position: line: 1, column: 23, offset: 22} for query: 'MATCH (s:`Session`)-[:LAST_MESSAGE]->(last_message) WHERE s.id = $session_id MATCH p=(last_message)<-[:NEXT*0..6]-() WITH p, length(p) AS length ORDER BY length DESC LIMIT 1 UNWIND reverse(nodes(p)) AS node RETURN {data:{content: node.content}, type:node.type} AS result'\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownRelationshipTypeWarning} {category: UNRECOGNIZED} {title: The provided relationship type is not in the database.} {description: One of the relationship types in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing relationship type is: NEXT)} {position: line: 1, column: 104, offset: 103} for query: 'MATCH (s:`Session`)-[:LAST_MESSAGE]->(last_message) WHERE s.id = $session_id MATCH p=(last_message)<-[:NEXT*0..6]-() WITH p, length(p) AS length ORDER BY length DESC LIMIT 1 UNWIND reverse(nodes(p)) AS node RETURN {data:{content: node.content}, type:node.type} AS result'\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: content)} {position: line: 1, column: 236, offset: 235} for query: 'MATCH (s:`Session`)-[:LAST_MESSAGE]->(last_message) WHERE s.id = $session_id MATCH p=(last_message)<-[:NEXT*0..6]-() WITH p, length(p) AS length ORDER BY length DESC LIMIT 1 UNWIND reverse(nodes(p)) AS node RETURN {data:{content: node.content}, type:node.type} AS result'\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: type)} {position: line: 1, column: 256, offset: 255} for query: 'MATCH (s:`Session`)-[:LAST_MESSAGE]->(last_message) WHERE s.id = $session_id MATCH p=(last_message)<-[:NEXT*0..6]-() WITH p, length(p) AS length ORDER BY length DESC LIMIT 1 UNWIND reverse(nodes(p)) AS node RETURN {data:{content: node.content}, type:node.type} AS result'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-dc0214e374f4>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     response = chat_agent.invoke(\n\u001b[0m\u001b[1;32m     73\u001b[0m         {\n\u001b[1;32m     74\u001b[0m             \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5333\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5334\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5335\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5336\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5337\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5333\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5334\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5335\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5336\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5337\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3018\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3020\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3021\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3022\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5333\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5334\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5335\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5336\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5337\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4696\u001b[0m         \"\"\"\n\u001b[1;32m   4697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4698\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m   4699\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4700\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1922\u001b[0m             output = cast(\n\u001b[1;32m   1923\u001b[0m                 \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m                 context.run(\n\u001b[0m\u001b[1;32m   1925\u001b[0m                     \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4562\u001b[0m                     \u001b[0;34mf\"Recursion limit reached when invoking {self} with input {input}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4563\u001b[0m                 )\n\u001b[0;32m-> 4564\u001b[0;31m             output = output.invoke(\n\u001b[0m\u001b[1;32m   4565\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4566\u001b[0m                 patch_config(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5333\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5334\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5335\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5336\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5337\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             outputs = (\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1630\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1334\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1335\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1336\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m                 for a in self._iter_next_step(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1334\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1335\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1336\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m                 for a in self._iter_next_step(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m             output = self._action_agent.plan(\n\u001b[0m\u001b[1;32m   1364\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0;31m# Because the response from the plan is not a generator, we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;31m# accumulate the output into final output and return that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfinal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                     \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3401\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3402\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3403\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3405\u001b[0m     async def atransform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3388\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3389\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3390\u001b[0;31m         yield from self._transform_stream_with_config(\n\u001b[0m\u001b[1;32m   3391\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3392\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2192\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2193\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2194\u001b[0;31m                     \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2195\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfinal_output_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3351\u001b[0m                 \u001b[0mfinal_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3353\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3355\u001b[0m     async def _atransform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0mgot_first_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0michunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m             \u001b[0;31m# The default implementation of transform is to buffer input and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m             \u001b[0;31m# then call stream.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5540\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5541\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 5542\u001b[0;31m         yield from self.bound.transform(\n\u001b[0m\u001b[1;32m   5543\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5544\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgot_first_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1428\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m     async def atransform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m                     ),\n\u001b[1;32m    417\u001b[0m                 )\n\u001b[0;32m--> 418\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                         \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"run-{run_manager.run_id}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_stream\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0mbase_generation_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0mis_first_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    740\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    741\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    743\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         )\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrievers\n",
        "\n",
        "Let's first see how the similarity search works at Neo4j (no LLMs involved in the below cell)."
      ],
      "metadata": {
        "id": "R7QlMk5-m3JK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "\n",
        "embedding_provider = OpenAIEmbeddings(\n",
        "    openai_api_key=\"sk-...\"\n",
        ")\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=\"bolt://18.233.226.221:7687\",\n",
        "    username=\"neo4j\",\n",
        "    password=\"monitors-terminators-mile\"\n",
        ")\n",
        "\n",
        "movie_plot_vector = Neo4jVector.from_existing_index(\n",
        "    embedding_provider,\n",
        "    graph=graph,\n",
        "    index_name=\"moviePlots\",\n",
        "    embedding_node_property=\"plotEmbedding\",\n",
        "    text_node_property=\"plot\",\n",
        ")\n",
        "\n",
        "result = movie_plot_vector.similarity_search(\"A movie where aliens land and attack earth.\") #query, k=4\n",
        "for doc in result:\n",
        "    print(doc.metadata[\"title\"], \"-\", doc.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "_oYqdghxm5NG",
        "outputId": "e447479a-7e8f-49ae-be10-49a7835eaf94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_openai'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d61e2079e88f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeo4jGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeo4jVector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m embedding_provider = OpenAIEmbeddings(\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_openai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Additional] Neo4j index at runtime\n",
        "\n",
        "For reference only if you wish to create an index at runtime. The below cell isn't used in this course, so you may skip this."
      ],
      "metadata": {
        "id": "A0Gu2vV2sEUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain.schema import Document\n",
        "\n",
        "# A list of Documents\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\"Text to be indexed\",\n",
        "        metadata={\"source\": \"local\"}\n",
        "    )\n",
        "]\n",
        "\n",
        "# Service used to create the embeddings\n",
        "embedding_provider = OpenAIEmbeddings(\n",
        "    openai_api_key=\"sk-...\"\n",
        ")\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=\"bolt://18.233.226.221:7687\",\n",
        "    username=\"neo4j\",\n",
        "    password=\"monitors-terminators-mile\"\n",
        ")\n",
        "\n",
        "new_vector = Neo4jVector.from_documents(\n",
        "    documents,\n",
        "    embedding_provider,\n",
        "    graph=graph,\n",
        "    index_name=\"myVectorIndex\",\n",
        "    node_label=\"Chunk\",\n",
        "    text_node_property=\"text\",\n",
        "    embedding_node_property=\"embedding\",\n",
        "    create_id_index=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "afoEePmisIWy",
        "outputId": "2f84f5ab-bec6-41bc-bcfe-842072e20fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_openai'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4017159e9d88>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeo4jGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeo4jVector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_openai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full RetrievalQA chain\n",
        "\n",
        "The retriever, now with LLMs (no agents involved in the below cell)."
      ],
      "metadata": {
        "id": "I39pwzoX3DFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "\n",
        "OPENAI_API_KEY = \"sk-...\"\n",
        "\n",
        "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "embedding_provider = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=\"bolt://18.233.226.221:7687\",\n",
        "    username=\"neo4j\",\n",
        "    password=\"monitors-terminators-mile\"\n",
        ")\n",
        "\n",
        "movie_plot_vector = Neo4jVector.from_existing_index(\n",
        "    embedding_provider,\n",
        "    graph=graph,\n",
        "    index_name=\"moviePlots\",\n",
        "    embedding_node_property=\"plotEmbedding\",\n",
        "    text_node_property=\"plot\",\n",
        ")\n",
        "\n",
        "plot_retriever = RetrievalQA.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=movie_plot_vector.as_retriever(),\n",
        "    #  verbose=True,\n",
        "    # return_source_documents=True\n",
        ")\n",
        "\n",
        "response = plot_retriever.invoke(\n",
        "    {\"query\": \"A movie where a mission to the moon goes wrong\"}\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "7qU6iZtk201D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [MAIN CODE] RetrieverQA + Agents (Optional Exercise)\n",
        "The main code, combining the \"intelligent\" agent with retrievers for your RAG application."
      ],
      "metadata": {
        "id": "2onNUexwrTbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain.tools import Tool\n",
        "from langchain import hub\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain_community.tools import YouTubeSearchTool\n",
        "from langchain_community.chat_message_histories import Neo4jChatMessageHistory\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from uuid import uuid4\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "\n",
        "\n",
        "SESSION_ID = str(uuid4())\n",
        "print(f\"Session ID: {SESSION_ID}\")\n",
        "\n",
        "llm = ChatOpenAI(openai_api_key=\"sk-...\")\n",
        "\n",
        "embedding_provider = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=\"neo4j://3.84.134.243:7687\",\n",
        "    username=\"neo4j\",\n",
        "    password=\"tuition-experiences-colors\"\n",
        ")\n",
        "\n",
        "\n",
        "movie_plot_vector = Neo4jVector.from_existing_index(\n",
        "    embedding_provider,\n",
        "    graph=graph,\n",
        "    index_name=\"moviePlots\",\n",
        "    embedding_node_property=\"plotEmbedding\",\n",
        "    text_node_property=\"plot\",\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a movie expert. You find movies from a genre or plot.\",\n",
        "        ),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "plot_retriever = RetrievalQA.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=movie_plot_vector.as_retriever(),\n",
        "     verbose=True,\n",
        "    return_source_documents=True\n",
        ")\n",
        "response = plot_retriever.invoke(\n",
        "    {\"query\": \"A movie where a mission to the moon goes wrong\"}\n",
        ")\n",
        "print(response)\n",
        "\n",
        "movie_chat = prompt | llm | StrOutputParser()\n",
        "\n",
        "youtube = YouTubeSearchTool()\n",
        "\n",
        "def get_memory(session_id):\n",
        "    return Neo4jChatMessageHistory(session_id=session_id, graph=graph)\n",
        "\n",
        "\n",
        "def call_trailer_search(input):\n",
        "    input = input.replace(\",\", \" \")\n",
        "    return youtube.run(input)\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        name=\"Movie Chat\",\n",
        "        description=\"For when you need to chat about movies. The question will be a string. Return a string.\",\n",
        "        func=movie_chat.invoke,\n",
        "    ),\n",
        "    Tool.from_function(\n",
        "        name=\"Movie Trailer Search\",\n",
        "        description=\"Use when needing to find a movie trailer. The question will include the word trailer. Return a link to a YouTube video.\",\n",
        "        func=call_trailer_search,\n",
        "    ),\n",
        "    Tool.from_function( #RAG\n",
        "        name=\"Movie Plot Search\",\n",
        "        description=\"For when you need to compare a plot to a movie. The question will be a string. Return a string.\",\n",
        "        func=plot_retriever.invoke, #I was putting this in place of the first tool func, but realization is that the prompt description also matters - the word \"compare\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "agent_prompt = hub.pull(\"hwchase17/react-chat\") #https://smith.langchain.com/hub/hwchase17/react-chat?organizationId=d9a804f5-9c91-5073-8980-3d7112f1cbd3\n",
        "agent = create_react_agent(llm, tools, agent_prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose = True )  # max_iterations=3,    verbose=True,    handle_parse_errors=True\n",
        "\n",
        "chat_agent = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    get_memory,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")\n",
        "\n",
        "while True:\n",
        "    q = input(\"> \")\n",
        "\n",
        "    response = chat_agent.invoke(\n",
        "        {\n",
        "            \"input\": q\n",
        "        },\n",
        "        {\"configurable\": {\"session_id\": SESSION_ID}},\n",
        "    )\n",
        "\n",
        "    print(response[\"output\"])"
      ],
      "metadata": {
        "id": "cETWoLYwKC8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [DEMO] With Falcon\n",
        "\n",
        "The main code, but with our created embeddings and an accessible LLM (both open-source).\n"
      ],
      "metadata": {
        "id": "9WxCAmBXKBae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "from langchain import HuggingFaceHub\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"hf_....\" #Put your own HF API here - it's free!\n",
        "\n",
        "llm=HuggingFaceHub(repo_id=\"tiiuae/falcon-7b-instruct\", model_kwargs={\"temperature\":0.01}) #Play around with the temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBKvET7lbfdv",
        "outputId": "a4c582c3-f8ab-4fa7-ef0b-6c492440b6e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-2baf26512d0c>:9: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
            "  llm=HuggingFaceHub(repo_id=\"tiiuae/falcon-7b-instruct\", model_kwargs={\"temperature\":0.01}) #Play around with the temp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"What is the meaning of the word \\\"model\\\"?\") #Sanity check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "w9IrgzoUg6rA",
        "outputId": "4cdcd737-93b5-4ac4-b5b1-ad0573b47462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the meaning of the word \"model\"?\\nThe word \"model\" can refer to a physical or ideal representation of something, or a set of instructions or guidelines for achieving a particular goal. It can also refer to a specific type of model, such as a mathematical model or a scientific model.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain.tools import Tool\n",
        "from langchain import hub\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain_community.tools import YouTubeSearchTool\n",
        "from langchain_community.chat_message_histories import Neo4jChatMessageHistory\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from uuid import uuid4\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "SESSION_ID = str(uuid4())\n",
        "print(f\"Session ID: {SESSION_ID}\")\n",
        "\n",
        "\n",
        "embedding_provider = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=\"bolt://44.220.93.128:7687\",\n",
        "    username=\"neo4j\",\n",
        "    password=\"mechanisms-facility-nose\"\n",
        ")\n",
        "\n",
        "\n",
        "movie_plot_vector = Neo4jVector.from_existing_index(\n",
        "    embedding_provider,\n",
        "    graph=graph,\n",
        "    index_name=\"moviePlots\",\n",
        "    embedding_node_property=\"plotEmbedding\",\n",
        "    text_node_property=\"plot\",\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a movie expert. You find movies from a genre or plot.\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "template = \"\"\"\n",
        "TOOLS:\n",
        "\n",
        "------\n",
        "\n",
        "You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "CHOOSE ONE FROM {tool_names} for the \"Action\".\n",
        "\n",
        "Action: Movie Plot Search\n",
        "Action Input: {input}\n",
        "Observation: the result of the action\n",
        "\n",
        "```\n",
        "\n",
        "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
        "\n",
        "```\n",
        "Thought: Do I need to use a tool? No\n",
        "\n",
        "Final Answer: [your response here]\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "Begin!\n",
        "\n",
        "\n",
        "\n",
        "New input: {input}\n",
        "\n",
        "{agent_scratchpad}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "agent_prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "\n",
        "plot_retriever = RetrievalQA.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=movie_plot_vector.as_retriever(),\n",
        "     verbose=True,\n",
        "    return_source_documents=True\n",
        ")\n",
        "# response = plot_retriever.invoke(\n",
        "#     {\"query\": \"A movie where a mission to the moon goes wrong\"}\n",
        "# )\n",
        "# print(response)\n",
        "\n",
        "movie_chat = prompt | llm | StrOutputParser()\n",
        "\n",
        "youtube = YouTubeSearchTool()\n",
        "\n",
        "# def get_memory(session_id): #persisting memory\n",
        "#     return Neo4jChatMessageHistory(session_id=session_id, graph=graph)\n",
        "\n",
        "#You may use the below messgae history if you don't want to keep polluting your Sandbox with different session runs for persistence (each time you run this cell, a new session is made)\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "\n",
        "memory = ChatMessageHistory() #ephemeral memory for the current session\n",
        "\n",
        "def get_memory(session_id):\n",
        "    return memory\n",
        "\n",
        "def call_trailer_search(input):\n",
        "    input = input.replace(\",\", \" \")\n",
        "    return youtube.run(input)\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        name=\"Movie Chat\",\n",
        "        description=\"For when you need to chat about movies. The question will be a string. Return a string.\",\n",
        "        func=movie_chat.invoke,\n",
        "    ),\n",
        "    Tool.from_function(\n",
        "        name=\"Movie Trailer Search\",\n",
        "        description=\"Use when needing to find a movie trailer. The question will include the word trailer. Return a link to a YouTube video.\",\n",
        "        func=call_trailer_search,\n",
        "    ),\n",
        "    Tool.from_function( #RAG\n",
        "        name=\"Movie Plot Search\",\n",
        "        description=\"Use when retrieving the title for a given plot. The question will include the word title. Return the closest matched plot's title from the context you are given.\",\n",
        "        func=plot_retriever.invoke, #I was putting this in place of the first tool func, but realization is that the prompt description also matters - the word \"compare\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "agent = create_react_agent(llm, tools, agent_prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose = True, max_iterations=3, handle_parsing_errors=True, use_function_response=True )  # max_iterations=3,    verbose=True,    handle_parse_errors=True\n",
        "\n",
        "chat_agent = RunnableWithMessageHistory(\n",
        "    agent_executor, #If no agent, direct chain also (movie_chat)\n",
        "    get_memory,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")\n",
        "\n",
        "while True:\n",
        "    q = input(\"> \")\n",
        "\n",
        "    response = chat_agent.invoke( #or can do a direct agent_executor.invoke if u do not want the memory / movie_chat if u do not want the agent\n",
        "        {\n",
        "            \"input\": q\n",
        "        },\n",
        "        {\"configurable\": {\"session_id\": SESSION_ID}},\n",
        "    )\n",
        "\n",
        "    print(response['output'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rF_mRMunrZ6W",
        "outputId": "4cbf1ebe-17bc-4d90-e5e5-00ba46fd87bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session ID: 4e58005e-959b-4536-987c-08405ded8eb7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> A movie about a cowboy doll and a spaceman toy.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mHuman: \n",
            "TOOLS:\n",
            "\n",
            "------\n",
            "\n",
            "You have access to the following tools:\n",
            "\n",
            "Movie Chat(input: 'Input', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Any') -> 'Output' - For when you need to chat about movies. The question will be a string. Return a string.\n",
            "Movie Trailer Search(input) - Use when needing to find a movie trailer. The question will include the word trailer. Return a link to a YouTube video.\n",
            "Movie Plot Search(input: Dict[str, Any], config: Optional[langchain_core.runnables.config.RunnableConfig] = None, **kwargs: Any) -> Dict[str, Any] - Use when retrieving the title for a given plot. The question will include the word title. Return the closest matched plot's title from the context you are given.\n",
            "\n",
            "CHOOSE ONE FROM Movie Chat, Movie Trailer Search, Movie Plot Search for the \"Action\".\n",
            "\n",
            "Action: Movie Plot Search\n",
            "Action Input: A movie about a cowboy doll and a spaceman toy.\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[38;5;200m\u001b[1;3m{'query': 'A movie about a cowboy doll and a spaceman toy.', 'result': \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nContext:\\nA cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.\\n\\nContext:\\nA young bald albino boy with unique powers shakes up the rural community he lives in.\\n\\nContext:\\nFocusing on a trio of friends and their elaborate plan to pull off a simple robbery and go on the run.\\n\\nContext:\\nA single and lonely woman finds the seemingly perfect man to date, but soon regrets it when his deranged and possessive other personality emerges and worst still, she cannot convince anyone else of his Jekyll/Hyde true nature.\\n\\nQuestion: A movie about a cowboy doll and a spaceman toy.\\nHelpful Answer: The movie is 'Toy Story'.\", 'source_documents': [Document(metadata={'budget': 30000000, 'movieId': '1', 'tmdbId': '862', 'imdbVotes': 591836, 'runtime': 81, 'countries': ['USA'], 'imdbId': '0114709', 'url': 'https://themoviedb.org/movie/862', 'released': '1995-11-22', 'languages': ['English'], 'imdbRating': 8.3, 'title': 'Toy Story', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg', 'year': 1995, 'revenue': 373554033}, page_content=\"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.\"), Document(metadata={'movieId': '24', 'tmdbId': '12665', 'imdbVotes': 23715, 'runtime': 111, 'countries': ['USA'], 'imdbId': '0114168', 'url': 'https://themoviedb.org/movie/12665', 'released': '1995-10-27', 'languages': ['English'], 'imdbRating': 6.5, 'title': 'Powder', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/kImKATjY4EsK5MDgrmpJdGbQEbq.jpg', 'year': 1995}, page_content='A young bald albino boy with unique powers shakes up the rural community he lives in.'), Document(metadata={'budget': 7000000, 'movieId': '101', 'tmdbId': '13685', 'imdbVotes': 52853, 'runtime': 91, 'countries': ['USA'], 'imdbId': '0115734', 'url': 'https://themoviedb.org/movie/13685', 'released': '1996-02-21', 'languages': ['English', ' Spanish'], 'imdbRating': 7.1, 'title': 'Bottle Rocket', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/9ZTDOI0CB1WABPMH2zV5Gd5g414.jpg', 'year': 1996, 'revenue': 560069}, page_content='Focusing on a trio of friends and their elaborate plan to pull off a simple robbery and go on the run.'), Document(metadata={'movieId': '102', 'tmdbId': '47475', 'imdbVotes': 4235, 'runtime': 96, 'countries': ['USA'], 'imdbId': '0117102', 'url': 'https://themoviedb.org/movie/47475', 'released': '1996-02-16', 'languages': ['English'], 'imdbRating': 3.7, 'title': 'Mr. Wrong', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/yGbPzJ5hib2TFi0Rkb6JH8webaL.jpg', 'year': 1996}, page_content='A single and lonely woman finds the seemingly perfect man to date, but soon regrets it when his deranged and possessive other personality emerges and worst still, she cannot convince anyone else of his Jekyll/Hyde true nature.')]}\u001b[0m\u001b[32;1m\u001b[1;3mHuman: \n",
            "TOOLS:\n",
            "\n",
            "------\n",
            "\n",
            "You have access to the following tools:\n",
            "\n",
            "Movie Chat(input: 'Input', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Any') -> 'Output' - For when you need to chat about movies. The question will be a string. Return a string.\n",
            "Movie Trailer Search(input) - Use when needing to find a movie trailer. The question will include the word trailer. Return a link to a YouTube video.\n",
            "Movie Plot Search(input: Dict[str, Any], config: Optional[langchain_core.runnables.config.RunnableConfig] = None, **kwargs: Any) -> Dict[str, Any] - Use when retrieving the title for a given plot. The question will include the word title. Return the closest matched plot's title from the context you are given.\n",
            "\n",
            "CHOOSE ONE FROM Movie Chat, Movie Trailer Search, Movie Plot Search for the \"Action\".\n",
            "\n",
            "Action: Movie Plot Search\n",
            "Action Input: A movie about a cowboy doll and a spaceman toy.\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[38;5;200m\u001b[1;3m{'query': 'A movie about a cowboy doll and a spaceman toy.', 'result': \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nContext:\\nA cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.\\n\\nContext:\\nA young bald albino boy with unique powers shakes up the rural community he lives in.\\n\\nContext:\\nFocusing on a trio of friends and their elaborate plan to pull off a simple robbery and go on the run.\\n\\nContext:\\nA single and lonely woman finds the seemingly perfect man to date, but soon regrets it when his deranged and possessive other personality emerges and worst still, she cannot convince anyone else of his Jekyll/Hyde true nature.\\n\\nQuestion: A movie about a cowboy doll and a spaceman toy.\\nHelpful Answer: The movie is 'Toy Story'.\", 'source_documents': [Document(metadata={'budget': 30000000, 'movieId': '1', 'tmdbId': '862', 'imdbVotes': 591836, 'runtime': 81, 'countries': ['USA'], 'imdbId': '0114709', 'url': 'https://themoviedb.org/movie/862', 'released': '1995-11-22', 'languages': ['English'], 'imdbRating': 8.3, 'title': 'Toy Story', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg', 'year': 1995, 'revenue': 373554033}, page_content=\"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.\"), Document(metadata={'movieId': '24', 'tmdbId': '12665', 'imdbVotes': 23715, 'runtime': 111, 'countries': ['USA'], 'imdbId': '0114168', 'url': 'https://themoviedb.org/movie/12665', 'released': '1995-10-27', 'languages': ['English'], 'imdbRating': 6.5, 'title': 'Powder', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/kImKATjY4EsK5MDgrmpJdGbQEbq.jpg', 'year': 1995}, page_content='A young bald albino boy with unique powers shakes up the rural community he lives in.'), Document(metadata={'budget': 7000000, 'movieId': '101', 'tmdbId': '13685', 'imdbVotes': 52853, 'runtime': 91, 'countries': ['USA'], 'imdbId': '0115734', 'url': 'https://themoviedb.org/movie/13685', 'released': '1996-02-21', 'languages': ['English', ' Spanish'], 'imdbRating': 7.1, 'title': 'Bottle Rocket', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/9ZTDOI0CB1WABPMH2zV5Gd5g414.jpg', 'year': 1996, 'revenue': 560069}, page_content='Focusing on a trio of friends and their elaborate plan to pull off a simple robbery and go on the run.'), Document(metadata={'movieId': '102', 'tmdbId': '47475', 'imdbVotes': 4235, 'runtime': 96, 'countries': ['USA'], 'imdbId': '0117102', 'url': 'https://themoviedb.org/movie/47475', 'released': '1996-02-16', 'languages': ['English'], 'imdbRating': 3.7, 'title': 'Mr. Wrong', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/yGbPzJ5hib2TFi0Rkb6JH8webaL.jpg', 'year': 1996}, page_content='A single and lonely woman finds the seemingly perfect man to date, but soon regrets it when his deranged and possessive other personality emerges and worst still, she cannot convince anyone else of his Jekyll/Hyde true nature.')]}\u001b[0m\u001b[32;1m\u001b[1;3mHuman: \n",
            "TOOLS:\n",
            "\n",
            "------\n",
            "\n",
            "You have access to the following tools:\n",
            "\n",
            "Movie Chat(input: 'Input', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Any') -> 'Output' - For when you need to chat about movies. The question will be a string. Return a string.\n",
            "Movie Trailer Search(input) - Use when needing to find a movie trailer. The question will include the word trailer. Return a link to a YouTube video.\n",
            "Movie Plot Search(input: Dict[str, Any], config: Optional[langchain_core.runnables.config.RunnableConfig] = None, **kwargs: Any) -> Dict[str, Any] - Use when retrieving the title for a given plot. The question will include the word title. Return the closest matched plot's title from the context you are given.\n",
            "\n",
            "CHOOSE ONE FROM Movie Chat, Movie Trailer Search, Movie Plot Search for the \"Action\".\n",
            "\n",
            "Action: Movie Plot Search\n",
            "Action Input: A movie about a cowboy doll and a spaceman toy.\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[38;5;200m\u001b[1;3m{'query': 'A movie about a cowboy doll and a spaceman toy.', 'result': \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nContext:\\nA cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.\\n\\nContext:\\nA young bald albino boy with unique powers shakes up the rural community he lives in.\\n\\nContext:\\nFocusing on a trio of friends and their elaborate plan to pull off a simple robbery and go on the run.\\n\\nContext:\\nA single and lonely woman finds the seemingly perfect man to date, but soon regrets it when his deranged and possessive other personality emerges and worst still, she cannot convince anyone else of his Jekyll/Hyde true nature.\\n\\nQuestion: A movie about a cowboy doll and a spaceman toy.\\nHelpful Answer: The movie is 'Toy Story'.\", 'source_documents': [Document(metadata={'budget': 30000000, 'movieId': '1', 'tmdbId': '862', 'imdbVotes': 591836, 'runtime': 81, 'countries': ['USA'], 'imdbId': '0114709', 'url': 'https://themoviedb.org/movie/862', 'released': '1995-11-22', 'languages': ['English'], 'imdbRating': 8.3, 'title': 'Toy Story', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg', 'year': 1995, 'revenue': 373554033}, page_content=\"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.\"), Document(metadata={'movieId': '24', 'tmdbId': '12665', 'imdbVotes': 23715, 'runtime': 111, 'countries': ['USA'], 'imdbId': '0114168', 'url': 'https://themoviedb.org/movie/12665', 'released': '1995-10-27', 'languages': ['English'], 'imdbRating': 6.5, 'title': 'Powder', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/kImKATjY4EsK5MDgrmpJdGbQEbq.jpg', 'year': 1995}, page_content='A young bald albino boy with unique powers shakes up the rural community he lives in.'), Document(metadata={'budget': 7000000, 'movieId': '101', 'tmdbId': '13685', 'imdbVotes': 52853, 'runtime': 91, 'countries': ['USA'], 'imdbId': '0115734', 'url': 'https://themoviedb.org/movie/13685', 'released': '1996-02-21', 'languages': ['English', ' Spanish'], 'imdbRating': 7.1, 'title': 'Bottle Rocket', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/9ZTDOI0CB1WABPMH2zV5Gd5g414.jpg', 'year': 1996, 'revenue': 560069}, page_content='Focusing on a trio of friends and their elaborate plan to pull off a simple robbery and go on the run.'), Document(metadata={'movieId': '102', 'tmdbId': '47475', 'imdbVotes': 4235, 'runtime': 96, 'countries': ['USA'], 'imdbId': '0117102', 'url': 'https://themoviedb.org/movie/47475', 'released': '1996-02-16', 'languages': ['English'], 'imdbRating': 3.7, 'title': 'Mr. Wrong', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/yGbPzJ5hib2TFi0Rkb6JH8webaL.jpg', 'year': 1996}, page_content='A single and lonely woman finds the seemingly perfect man to date, but soon regrets it when his deranged and possessive other personality emerges and worst still, she cannot convince anyone else of his Jekyll/Hyde true nature.')]}\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Agent stopped due to iteration limit or time limit.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-400ac8eef95b>\u001b[0m in \u001b[0;36m<cell line: 145>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     response = chat_agent.invoke( #or can do a direct agent_executor.invoke if u do not want the memory / movie_chat if u do not want the agent\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that in the prompt, \"Action\" and \"Action Input\" must be present in the same casing. While the original prompt expects the LLM to choose one of the tools, our LLM simply resorts to passing down to the agent the exact string present after \"Action\" instead of reasoning over it. Thus, I needed to hardcode it. The same goes for the Action Input. The LLM / agent also doesn't return the actual output in the format we expect, which can be seen when you harcode either of the three tools in Action (copy any one of the three tool names there).\n",
        "\n",
        "- You may note that when given the plot search tool, the tool certainly enters the RetrievalQA chain, and gives a response with the retrieved documents. Infact, it correctly retrieves all plots given from the source document as context and at at the end, under \"Helpful Answer\", correctly gives the title (highly dependent on the way the user input was worded). However, it seems that the response isn't being parsed back to the agent executor call, which is still waiting for a reply and hence times out. The same issue seems to happen for the simpler chat invoke, and again for when the YT links are returned - though all three tools do their part.\n",
        "\n",
        "Overall, the LLM is unable to reason through the agent, perhaps because the 7B-instruct was developed for conversations instead of internal reasoning. (Feel free to try out the offline (non-HFAPI) model of 40B and see if it can work!)\n",
        "\n",
        "Each iteration shows the thinking of the model. To disable the output, switch \"verbose\" to `False` in the agent_executor."
      ],
      "metadata": {
        "id": "ybqTU9fPOVD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cypher for returning graph of the conv history (as earlier stored in Neo4j)**\n",
        "\n",
        "Execute these on the sandbox website (refer to the course for what these do):\n",
        "\n",
        "\n",
        "- MATCH (s:Session)-[:LAST_MESSAGE]->(last:Message)<-[:NEXT*]-(msg:Message)\n",
        "RETURN s, last, msg\n",
        "\n",
        "- MATCH (s:Session)-[:LAST_MESSAGE]->(last:Message)\n",
        "WHERE s.id = 'your session id'\n",
        "MATCH p = (last)<-[:NEXT*]-(msg:Message)\n",
        "UNWIND nodes(p) as msgs\n",
        "RETURN DISTINCT msgs.type, msgs.content"
      ],
      "metadata": {
        "id": "kcLx-Y1pJTus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [CHAT] Falcon + Neo4j RAG without agents"
      ],
      "metadata": {
        "id": "P61zOYnbPf6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.schema import StrOutputParser\n",
        "from operator import itemgetter\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from uuid import uuid4\n",
        "\n",
        "SESSION_ID = str(uuid4())\n",
        "print(f\"Session ID: {SESSION_ID}\")\n",
        "\n",
        "memory = ChatMessageHistory() #ephemeral memory for the current session\n",
        "\n",
        "def get_memory(session_id):\n",
        "    return memory\n",
        "\n",
        "\n",
        "embedding_provider = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=\"bolt://44.220.93.128:7687\",\n",
        "    username=\"neo4j\",\n",
        "    password=\"mechanisms-facility-nose\"\n",
        ")\n",
        "\n",
        "\n",
        "movie_plot_vector = Neo4jVector.from_existing_index(\n",
        "    embedding_provider,\n",
        "    graph=graph,\n",
        "    index_name=\"moviePlots\",\n",
        "    embedding_node_property=\"plotEmbedding\",\n",
        "    text_node_property=\"plot\",\n",
        ")\n",
        "\n",
        "# prompt = ChatPromptTemplate.from_messages(\n",
        "#     [\n",
        "#         (\n",
        "#             \"system\",\n",
        "#             \"You are a movie expert with the knowledge given to you as context from the retrieval database. The human user gives a plot, which you must match with the plots given to you as context.\",\n",
        "#         ),\n",
        "#         (\"human\", \"{input}\"),\n",
        "#     ]\n",
        "# )\n",
        "template = \"\"\"\n",
        "You are a movie expert. You are given a context that has information about four movies, including their titles and plots.\n",
        "Choose only one movie from the context given whose plot best correlates with the human question given.\n",
        "Return only the title of your chosen movie.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "\n",
        "Chat History:\n",
        "{chat_history}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# plot_retriever = RetrievalQA.from_llm(\n",
        "#     llm=llm,\n",
        "#     retriever=movie_plot_vector.as_retriever(),\n",
        "#     prompt = prompt,\n",
        "#      verbose=True,\n",
        "#     return_source_documents=True\n",
        "# )\n",
        "retriever = movie_plot_vector.as_retriever()\n",
        "# response = plot_retriever.invoke(\n",
        "#     {\"query\": \"A movie where a mission to the moon goes wrong\"}\n",
        "# )\n",
        "# print(response)\n",
        "\n",
        "# movie_chat = prompt | llm | StrOutputParser()\n",
        "# movie_chat = prompt | llm | plot_retriever\n",
        "chain = RunnableParallel({ \"chat_history\": itemgetter(\"chat_history\"), \"query\": itemgetter(\"query\"), \"context\": itemgetter(\"query\") | retriever}) |  prompt | llm | StrOutputParser() # in chain chat_history is expected explicitly because runPar comes in and distorts what's in despite the MessageHistory\n",
        "chat_agent = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_memory,\n",
        "    input_messages_key=\"query\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")\n",
        "\n",
        "while True:\n",
        "    q = input(\"> \")\n",
        "\n",
        "    response = chat_agent.invoke(\n",
        "        {\n",
        "            \"query\": q,\n",
        "        },\n",
        "        {\"configurable\": {\"session_id\": SESSION_ID}},\n",
        "    )\n",
        "\n",
        "    print(response)\n",
        "\n",
        "# Issues: dict invoke doesn't work with retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "40c11fa4740d4fb8b4885501eb89590d",
            "7779d07c49234419a2248493884f1bc7",
            "946736e3196640c68f1b2c343dfbbfa3",
            "3588140ab6144256b737fa5ccd3e6b30",
            "9700d3e435ce44a3b4a3bbdff5c21ac6",
            "b903aaa2b76c4b51877244ca06d03cd6",
            "f7ed98b27756414cb78477d6b76c7326",
            "a908fb7dae2e4e6b945125d5e320fec2",
            "2a6364bee101494793c91b9683db1bb1",
            "dd94f378e2c44c129baaa4bc4ba6fd07",
            "2bd17708533b45539585631821291a0d",
            "9fa3f9cb869e484d8f0bcb95641db198",
            "2cf03303323748a4840b2d7ff49a669d",
            "b2fdd134559c49bc9719e64447563811",
            "f78641ac845046de98a8ce1e88426dcb",
            "874b6f5986f34ea3b831923a01eb93cb",
            "d5038f0d45e14507a743a2c85348383f",
            "9afe48225d2f49cf81249ff2cc5abeb8",
            "6e7680462c734787a11ff1f2c3e777f0",
            "f128fd556c674d8b9807030adc31868a",
            "995f29f5ae7a4bd1973f598f7ccbfaa1",
            "f3a0ba6f27a544a09ec51e2ee6163df4",
            "33fbf466b6b343df956e9267af34d426",
            "cec7667171f7404ebc29a0e28b4f63c6",
            "f47ede694bba47e9bc7737472fd412e1",
            "c45c67ca12a343de9b8f96fb08d38caf",
            "2dbd6f4fa9dd421cb08c0c0e4c896dbb",
            "7c49db9519d540adb25c5b5f65a7256e",
            "dd493ad0aed547a3bfdb41639414208a",
            "bcd7c4bf59d5462ba90255414be19660",
            "106a513278214de094b8e536ee81ab8a",
            "3dc4b2d8b1224aee89c4f780d48c5f84",
            "1b4f3b8e209546d4ac88cdea2b904f2b",
            "a6bd35385b6d4ea996f2e20c2e688ffd",
            "7728b9ac8d2049e9a9d2be2544ae9699",
            "5f1682226fd74ba3b7e259dd4bb62d1c",
            "693af6a670d5460cb6f5c8440cfd196f",
            "585a8d7b0378498398549b2757dce889",
            "386423700b624fe5992535d38ba36087",
            "0a15fb33894248719e7ef5e3167ad228",
            "4ef915691e7c40d98072f43cba0f505d",
            "ca06e87f3136434e815394c626095e94",
            "35b14335fbc8448b88bfd92973c6aa13",
            "9cf5545ea5bf4bbeb3c5750fdcaba377",
            "d0bcb6a7978c404a87c7e0006129b6d2",
            "240bf5dd68b446d2af28bbda842ac67e",
            "75cb2f4a43964d2a9b50cafec29bd820",
            "283dd10c0fd74ad38a6e84a21adeb5d0",
            "a20fd8dc0add428ba15ba0f6294048cc",
            "c8eb98d5102a4f51874bf1ac55ba0b45",
            "acbe383506de48d0b6aac02262b8d57d",
            "9470b8386030499b84e44111ccc47e6c",
            "5f69f53e20de419c8e4dd6f88f056c98",
            "7d2ce24bbac34d219845483e1875a1d4",
            "10a791bc9ba44c2283553abba4226602",
            "019d31956865455687e60575d94b3ff7",
            "1d8115c836bc45d098eebc497616fcb7",
            "9b22a202679c43d4b6c4b1ed6a6a03fe",
            "0d044035afcb47d5b9fe154cf723a5a8",
            "ea023f49e40c4d3882cf15fc0f7e1dfa",
            "d39d32013c4a44ea9dfd3c136df155fd",
            "e2efa86ab58546d39128d229c4db8969",
            "f24b8d1fe05a4c4fa9f5ab7abd94b6e5",
            "36161eefe24a42f4ade9b21aa8e0a665",
            "a082790f4f7f4bc8b6e01dbf45ce851f",
            "6dce46f574e94327b4ee75762bc9f8df",
            "a2ae734b48c044c4a6cdb58cc5ed9bbd",
            "4f7f48fa8c494a5d90ffb18e4be48108",
            "499b303d42c14f56a301cf198bae0d9a",
            "b73a428f970a4cc89e3df3cce547916e",
            "1889c61a711c4b978de723be0e1f3f9e",
            "98a15d777a184239918231d2b5ca8580",
            "3d358c2120b345d5b985d4d81ee6ace5",
            "5c6801f39554431d941d403a252312e0",
            "d1e9ecd1269647b688daf9d7e44cedaa",
            "a8e214f3e89040fea96afbbef7389c8e",
            "8e325c7ceba94b16b7e726b8f0d80b51",
            "1ab7ffcaa3d949f6a937f25fd2fc99a3",
            "8e37c3a6da064b898f45621d32b1dd9f",
            "254c5dffe79d4ef8b9445706c7c0fa31",
            "6adeeda629854055beddc1406a9a8c31",
            "2c8ca15fb25d4ade99254b9d404584a2",
            "1ef1aeb286e04cd295e3c2e4c816454c",
            "8b43e3934e4e4395a9a59230a12e7af2",
            "9832fea6096e49b3bfef0667da8a63bb",
            "961f8d49fc154848b26aa36ae1e760c5",
            "c7ffbcae02f847109d8e02c6807fcef6",
            "fcb404ce451d43cf98b9df0b7db45dd2",
            "804cde193dc44517895eb009db3d205c",
            "9fe202cd78d44608ac092fba3e7648ee",
            "e06732725a0d4dbc8ba8e3e1f0f37097",
            "ca5a1703f752412bb687658edba9ef8a",
            "763be3765f254350af0335046704d57a",
            "c168e5317ee045e3b57e0ef500ae0144",
            "cc2c297bdf774ed38a27464c3eaa9866",
            "9113b0a583884162aa53a0f183a2465c",
            "be9d6f929b8b458cacf1fa6ed6ad737b",
            "937054df9979488faae4b06bb6f7ac47",
            "c61690c428234ff88c858d8608f118f3",
            "59365d4f01ad460ea23d75aeb8965e66",
            "53de40e447f841a9b48913c7731a2599",
            "56c9237eef1944d5b3969c728d6137a8",
            "c9c2f870ba5f4c6aa4a6fa8254fd38f6",
            "66e97736ba794223bea66e168cd80522",
            "a1ab5738f1f840eaa0681be3947507b8",
            "8efc6a3650704f06928981bb2cd5cc69",
            "e81c3600b18a47f180ae00895af3fcae",
            "daeeb094507a440aadb9e7d8a8d96605",
            "cbdf342163d040afbfc2f91803557a8a",
            "26866931e34d4f24a4b59a50900fd872",
            "faa54891b4b14d8ba5a3354e41b553ae",
            "967d12dafd9043d5aee075bf192c2cb6",
            "4bbe3d5e2b1c41f192ba0091d65f8d06",
            "89200d1d660941bdbda745d2f71a5ec7",
            "0064cd0d0fda44b6932fb84c0b0029b1",
            "dd4b61956a664cd381cbbd9898de07ff",
            "6e58d4611e39497683a7eecb60bf079a",
            "d15fbaecd3df4eb6a494e391261874f8",
            "c23d6d034a3d4055b642eaad32605d5b",
            "305301f2d05e4b8fbffdfd600811ca3c",
            "10d40ae9a1574fe99bde746a27edbb80"
          ]
        },
        "outputId": "9ec07328-b94e-4d54-9e97-604a6a8bd9f7",
        "id": "8Vd1WJk5PYAl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session ID: 4ced1bc7-90fe-49d3-a8d2-7011c34ba562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-860392a9880f>:25: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_provider = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40c11fa4740d4fb8b4885501eb89590d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fa3f9cb869e484d8f0bcb95641db198"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33fbf466b6b343df956e9267af34d426"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6bd35385b6d4ea996f2e20c2e688ffd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0bcb6a7978c404a87c7e0006129b6d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "019d31956865455687e60575d94b3ff7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2ae734b48c044c4a6cdb58cc5ed9bbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ab7ffcaa3d949f6a937f25fd2fc99a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "804cde193dc44517895eb009db3d205c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59365d4f01ad460ea23d75aeb8965e66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faa54891b4b14d8ba5a3354e41b553ae"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Tell me a title for a movie about a cowboy doll and a spaceman toy.\n",
            "Human: \n",
            "You are a movie expert. You are given a context that has information about four movies, including their titles and plots.\n",
            "Choose only one movie from the context given whose plot best correlates with the human question given.\n",
            "Return only the title of your chosen movie.\n",
            "\n",
            "Context:\n",
            "[Document(metadata={'budget': 30000000, 'movieId': '1', 'tmdbId': '862', 'imdbVotes': 591836, 'runtime': 81, 'countries': ['USA'], 'imdbId': '0114709', 'url': 'https://themoviedb.org/movie/862', 'released': '1995-11-22', 'languages': ['English'], 'imdbRating': 8.3, 'title': 'Toy Story', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg', 'year': 1995, 'revenue': 373554033}, page_content=\"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.\"), Document(metadata={'budget': 7000000, 'movieId': '101', 'tmdbId': '13685', 'imdbVotes': 52853, 'runtime': 91, 'countries': ['USA'], 'imdbId': '0115734', 'url': 'https://themoviedb.org/movie/13685', 'released': '1996-02-21', 'languages': ['English', ' Spanish'], 'imdbRating': 7.1, 'title': 'Bottle Rocket', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/9ZTDOI0CB1WABPMH2zV5Gd5g414.jpg', 'year': 1996, 'revenue': 560069}, page_content='Focusing on a trio of friends and their elaborate plan to pull off a simple robbery and go on the run.'), Document(metadata={'movieId': '107', 'tmdbId': '10874', 'imdbVotes': 15379, 'runtime': 99, 'countries': ['USA'], 'imdbId': '0117110', 'url': 'https://themoviedb.org/movie/10874', 'released': '1996-02-16', 'languages': ['English'], 'imdbRating': 6.9, 'title': 'Muppet Treasure Island', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/3TyhweCMltsQPQ2sfxNApe9RRRz.jpg', 'year': 1996, 'revenue': 34327391}, page_content=\"The Muppets' twist on the classic tale.\"), Document(metadata={'budget': 10000000, 'movieId': '104', 'tmdbId': '9614', 'imdbVotes': 150631, 'runtime': 92, 'countries': ['USA'], 'imdbId': '0116483', 'url': 'https://themoviedb.org/movie/9614', 'released': '1996-02-16', 'languages': ['English'], 'imdbRating': 7.0, 'title': 'Happy Gilmore', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/4RnCeRzvI1xk5tuNWjpDKzSnJDk.jpg', 'year': 1996, 'revenue': 41000000}, page_content=\"A rejected hockey player puts his skills to the golf course to save his grandmother's house.\")]\n",
            "\n",
            "\n",
            "Chat History:\n",
            "[]\n",
            "\n",
            "Question:\n",
            "Tell me a title for a movie about a cowboy doll and a spaceman toy.\n",
            "The movie is called \"Toy Story\".\n",
            "> What genre does this movie come in?\n",
            "Human: \n",
            "You are a movie expert. You are given a context that has information about four movies, including their titles and plots.\n",
            "Choose only one movie from the context given whose plot best correlates with the human question given.\n",
            "Return only the title of your chosen movie.\n",
            "\n",
            "Context:\n",
            "[Document(metadata={'budget': 16000000, 'movieId': '4', 'tmdbId': '31357', 'imdbVotes': 7210, 'runtime': 124, 'countries': ['USA'], 'imdbId': '0114885', 'url': 'https://themoviedb.org/movie/31357', 'released': '1995-12-22', 'languages': ['English'], 'imdbRating': 5.6, 'title': 'Waiting to Exhale', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/4wjGMwPsdlvi025ZqR4rXnFDvBz.jpg', 'year': 1995, 'revenue': 81452156}, page_content=\"Based on Terry McMillan's novel, this film follows four very different African-American women and their relationships with the male gender.\"), Document(metadata={'movieId': '12', 'tmdbId': '12110', 'imdbVotes': 29321, 'runtime': 88, 'countries': ['USA', ' France'], 'imdbId': '0112896', 'url': 'https://themoviedb.org/movie/12110', 'released': '1995-12-22', 'languages': ['English', ' German'], 'imdbRating': 5.8, 'title': 'Dracula: Dead and Loving It', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/4rRfZz8YnHNRr16t3CFcJrPdXHi.jpg', 'year': 1995}, page_content=\"Mel Brooks' parody of the classic vampire story and its famous film adaptations.\"), Document(metadata={'movieId': '74', 'tmdbId': '20927', 'imdbVotes': 6660, 'runtime': 87, 'countries': ['USA'], 'imdbId': '0115644', 'url': 'https://themoviedb.org/movie/20927', 'released': '1996-01-26', 'languages': ['English'], 'imdbRating': 6.0, 'title': 'Bed of Roses', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/e0Eho8TETw1RhvX9MH9i19Xf1iM.jpg', 'year': 1996, 'revenue': 19030691}, page_content='Romantic drama about a young career girl who is swept off her feet by a shy florist, who fell in love with her after one glimpse through a shadowy window.'), Document(metadata={'budget': 11000000, 'movieId': '36', 'tmdbId': '687', 'imdbVotes': 71231, 'runtime': 122, 'countries': ['UK', ' USA'], 'imdbId': '0112818', 'url': 'https://themoviedb.org/movie/687', 'released': '1996-02-02', 'languages': ['English'], 'imdbRating': 7.6, 'title': 'Dead Man Walking', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/wQmmJi5ypfHH2boXrQBmsep7qb2.jpg', 'year': 1995, 'revenue': 39363635}, page_content=\"A nun, while comforting a convicted killer on death row, empathizes with both the killer and his victim's families.\")]\n",
            "\n",
            "\n",
            "Chat History:\n",
            "[HumanMessage(content='Tell me a title for a movie about a cowboy doll and a spaceman toy.', additional_kwargs={}, response_metadata={}), AIMessage(content='Human: \\nYou are a movie expert. You are given a context that has information about four movies, including their titles and plots.\\nChoose only one movie from the context given whose plot best correlates with the human question given.\\nReturn only the title of your chosen movie.\\n\\nContext:\\n[Document(metadata={\\'budget\\': 30000000, \\'movieId\\': \\'1\\', \\'tmdbId\\': \\'862\\', \\'imdbVotes\\': 591836, \\'runtime\\': 81, \\'countries\\': [\\'USA\\'], \\'imdbId\\': \\'0114709\\', \\'url\\': \\'https://themoviedb.org/movie/862\\', \\'released\\': \\'1995-11-22\\', \\'languages\\': [\\'English\\'], \\'imdbRating\\': 8.3, \\'title\\': \\'Toy Story\\', \\'poster\\': \\'https://image.tmdb.org/t/p/w440_and_h660_face/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg\\', \\'year\\': 1995, \\'revenue\\': 373554033}, page_content=\"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy\\'s room.\"), Document(metadata={\\'budget\\': 7000000, \\'movieId\\': \\'101\\', \\'tmdbId\\': \\'13685\\', \\'imdbVotes\\': 52853, \\'runtime\\': 91, \\'countries\\': [\\'USA\\'], \\'imdbId\\': \\'0115734\\', \\'url\\': \\'https://themoviedb.org/movie/13685\\', \\'released\\': \\'1996-02-21\\', \\'languages\\': [\\'English\\', \\' Spanish\\'], \\'imdbRating\\': 7.1, \\'title\\': \\'Bottle Rocket\\', \\'poster\\': \\'https://image.tmdb.org/t/p/w440_and_h660_face/9ZTDOI0CB1WABPMH2zV5Gd5g414.jpg\\', \\'year\\': 1996, \\'revenue\\': 560069}, page_content=\\'Focusing on a trio of friends and their elaborate plan to pull off a simple robbery and go on the run.\\'), Document(metadata={\\'movieId\\': \\'107\\', \\'tmdbId\\': \\'10874\\', \\'imdbVotes\\': 15379, \\'runtime\\': 99, \\'countries\\': [\\'USA\\'], \\'imdbId\\': \\'0117110\\', \\'url\\': \\'https://themoviedb.org/movie/10874\\', \\'released\\': \\'1996-02-16\\', \\'languages\\': [\\'English\\'], \\'imdbRating\\': 6.9, \\'title\\': \\'Muppet Treasure Island\\', \\'poster\\': \\'https://image.tmdb.org/t/p/w440_and_h660_face/3TyhweCMltsQPQ2sfxNApe9RRRz.jpg\\', \\'year\\': 1996, \\'revenue\\': 34327391}, page_content=\"The Muppets\\' twist on the classic tale.\"), Document(metadata={\\'budget\\': 10000000, \\'movieId\\': \\'104\\', \\'tmdbId\\': \\'9614\\', \\'imdbVotes\\': 150631, \\'runtime\\': 92, \\'countries\\': [\\'USA\\'], \\'imdbId\\': \\'0116483\\', \\'url\\': \\'https://themoviedb.org/movie/9614\\', \\'released\\': \\'1996-02-16\\', \\'languages\\': [\\'English\\'], \\'imdbRating\\': 7.0, \\'title\\': \\'Happy Gilmore\\', \\'poster\\': \\'https://image.tmdb.org/t/p/w440_and_h660_face/4RnCeRzvI1xk5tuNWjpDKzSnJDk.jpg\\', \\'year\\': 1996, \\'revenue\\': 41000000}, page_content=\"A rejected hockey player puts his skills to the golf course to save his grandmother\\'s house.\")]\\n\\n\\nChat History:\\n[]\\n\\nQuestion:\\nTell me a title for a movie about a cowboy doll and a spaceman toy.\\nThe movie is called \"Toy Story\".', additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Question:\n",
            "What genre does this movie come in?\n",
            "The genre of the movie is a mix of comedy, animation, and drama.\n",
            "> Tell me the plot for a movie about finding treasure.\n",
            "Human: \n",
            "You are a movie expert. You are given a context that has information about four movies, including their titles and plots.\n",
            "Choose only one movie from the context given whose plot best correlates with the human question given.\n",
            "Return only the title of your chosen movie.\n",
            "\n",
            "Context:\n",
            "[Document(metadata={'movieId': '107', 'tmdbId': '10874', 'imdbVotes': 15379, 'runtime': 99, 'countries': ['USA'], 'imdbId': '0117110', 'url': 'https://themoviedb.org/movie/10874', 'released': '1996-02-16', 'languages': ['English'], 'imdbRating': 6.9, 'title': 'Muppet Treasure Island', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/3TyhweCMltsQPQ2sfxNApe9RRRz.jpg', 'year': 1996, 'revenue': 34327391}, page_content=\"The Muppets' twist on the classic tale.\"), Document(metadata={'budget': 7000000, 'movieId': '101', 'tmdbId': '13685', 'imdbVotes': 52853, 'runtime': 91, 'countries': ['USA'], 'imdbId': '0115734', 'url': 'https://themoviedb.org/movie/13685', 'released': '1996-02-21', 'languages': ['English', ' Spanish'], 'imdbRating': 7.1, 'title': 'Bottle Rocket', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/9ZTDOI0CB1WABPMH2zV5Gd5g414.jpg', 'year': 1996, 'revenue': 560069}, page_content='Focusing on a trio of friends and their elaborate plan to pull off a simple robbery and go on the run.'), Document(metadata={'budget': 98000000, 'movieId': '15', 'tmdbId': '1408', 'imdbVotes': 20522, 'runtime': 124, 'countries': ['USA', ' France', ' Italy', ' Germany'], 'imdbId': '0112760', 'url': 'https://themoviedb.org/movie/1408', 'released': '1995-12-22', 'languages': ['English'], 'imdbRating': 5.6, 'title': 'Cutthroat Island', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/hYdeBZ4BFXivdouxLfQGWNE6zRx.jpg', 'year': 1995, 'revenue': 10017322}, page_content='A female pirate and her companion race against their rivals to find a hidden island that contains a fabulous treasure.'), Document(metadata={'movieId': '98', 'tmdbId': '45549', 'imdbVotes': 2077, 'runtime': 87, 'countries': ['UK', ' Japan'], 'imdbId': '0111173', 'url': 'https://themoviedb.org/movie/45549', 'released': '1996-02-09', 'languages': ['English'], 'imdbRating': 5.4, 'title': 'Shopping', 'poster': 'https://image.tmdb.org/t/p/w440_and_h660_face/sE6oLJg2c9Wc9Ra7Yf5j7OArjYk.jpg', 'year': 1994}, page_content=\"You've run out of options, no school, no job. Steal a car, smash a shop with a heavy car and reap the proceeds!. This movie is about underground England. The causes, the benefits, and the result of a life of 'crash and carry'.\")]\n",
            "\n",
            "\n",
            "Chat History:\n",
            "[HumanMessage(content='Tell me a title for a movie about a cowboy doll and a spaceman toy.', additional_kwargs={}, response_metadata={}), AIMessage(content='Human: \\nYou are a movie expert. You are given a context that has information about four movies, including their titles and plots.\\nChoose only one movie from the context given whose plot best correlates with the human question given.\\nReturn only the title of your chosen movie.\\n\\nContext:\\n[Document(metadata={\\'budget\\': 30000000, \\'movieId\\': \\'1\\', \\'tmdbId\\': \\'862\\', \\'imdbVotes\\': 591836, \\'runtime\\': 81, \\'countries\\': [\\'USA\\'], \\'imdbId\\': \\'0114709\\', \\'url\\': \\'https://themoviedb.org/movie/862\\', \\'released\\': \\'1995-11-22\\', \\'languages\\': [\\'English\\'], \\'imdbRating\\': 8.3, \\'title\\': \\'Toy Story\\', \\'poster\\': \\'https://image.tmdb.org/t/p/w440_and_h660_face/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg\\', \\'year\\': 1995, \\'revenue\\': 373554033}, page_content=\"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy\\'s room.\"), Document(metadata={\\'budget\\': 7000000, \\'movieId\\': \\'101\\', \\'tmdbId\\': \\'13685\\', \\'imdbVotes\\': 52853, \\'runtime\\': 91, \\'countries\\': [\\'USA\\'], \\'imdbId\\': \\'0115734\\', \\'url\\': \\'https://themoviedb.org/movie/13685\\', \\'released\\': \\'1996-02-21\\', \\'languages\\': [\\'English\\', \\' Spanish\\'], \\'imdbRating\\': 7.1, \\'title\\': \\'Bottle Rocket\\', \\'poster\\': \\'https://image.tmdb.org/t/p/w440_and_h660_face/9ZTDOI0CB1WABPMH2zV5Gd5g414.jpg\\', \\'year\\': 1996, \\'revenue\\': 560069}, page_content=\\'Focusing on a trio of friends and their elaborate plan to pull off a simple robbery and go on the run.\\'), Document(metadata={\\'movieId\\': \\'107\\', \\'tmdbId\\': \\'10874\\', \\'imdbVotes\\': 15379, \\'runtime\\': 99, \\'countries\\': [\\'USA\\'], \\'imdbId\\': \\'0117110\\', \\'url\\': \\'https://themoviedb.org/movie/10874\\', \\'released\\': \\'1996-02-16\\', \\'languages\\': [\\'English\\'], \\'imdbRating\\': 6.9, \\'title\\': \\'Muppet Treasure Island\\', \\'poster\\': \\'https://image.tmdb.org/t/p/w440_and_h660_face/3TyhweCMltsQPQ2sfxNApe9RRRz.jpg\\', \\'year\\': 1996, \\'revenue\\': 34327391}, page_content=\"The Muppets\\' twist on the classic tale.\"), Document(metadata={\\'budget\\': 10000000, \\'movieId\\': \\'104\\', \\'tmdbId\\': \\'9614\\', \\'imdbVotes\\': 150631, \\'runtime\\': 92, \\'countries\\': [\\'USA\\'], \\'imdbId\\': \\'0116483\\', \\'url\\': \\'https://themoviedb.org/movie/9614\\', \\'released\\': \\'1996-02-16\\', \\'languages\\': [\\'English\\'], \\'imdbRating\\': 7.0, \\'title\\': \\'Happy Gilmore\\', \\'poster\\': \\'https://image.tmdb.org/t/p/w440_and_h660_face/4RnCeRzvI1xk5tuNWjpDKzSnJDk.jpg\\', \\'year\\': 1996, \\'revenue\\': 41000000}, page_content=\"A rejected hockey player puts his skills to the golf course to save his grandmother\\'s house.\")]\\n\\n\\nChat History:\\n[]\\n\\nQuestion:\\nTell me a title for a movie about a cowboy doll and a spaceman toy.\\nThe movie is called \"Toy Story\".', additional_kwargs={}, response_metadata={}), HumanMessage(content='What genre does this movie come in?', additional_kwargs={}, response_metadata={}), AIMessage(content='Human: \\nYou are a movie expert. You are given a context that has information about four movies, including their titles and plots.\\nChoose only one movie from the context given whose plot best correlates with the human question given.\\nReturn only the title of your chosen movie.\\n\\nContext:\\n[Document(metadata={\\'budget\\': 16000000, \\'movieId\\': \\'4\\', \\'tmdbId\\': \\'31357\\', \\'imdbVotes\\': 7210, \\'runtime\\': 124, \\'countries\\': [\\'USA\\'], \\'imdbId\\': \\'0114885\\', \\'url\\': \\'https://themoviedb.org/movie/31357\\', \\'released\\': \\'1995-12-22\\', \\'languages\\': [\\'English\\'], \\'imdbRating\\': 5.6, \\'title\\': \\'Waiting to Exhale\\', \\'poster\\': \\'https://image.tmdb.org/t/p/w440_and_h660_face/4wjGMwPsdlvi025ZqR4rXnFDvBz.jpg\\', \\'year\\': 1995, \\'revenue\\': 81452156}, page_content=\"Based on Terry McMillan\\'s novel, this film follows four very different African-American women and their relationships with the male gender.\"), Document(metadata={\\'movieId\\': \\'12\\', \\'tmdbId\\': \\'12110\\', \\'imdbVotes\\': 29321, \\'runtime\\': 88, \\'countries\\': [\\'USA\\', \\' France\\'], \\'imdbId\\': \\'0112896\\', \\'url\\': \\'https://themoviedb.org/movie/12110\\', \\'released\\': \\'1995-12-22\\', \\'languages\\': [\\'English\\', \\' German\\'], \\'imdbRating\\': 5.8, \\'title\\': \\'Dracula: Dead and Loving It\\', \\'poster\\': \\'https://image.tmdb.org/t/p/w440_and_h660_face/4rRfZz8YnHNRr16t3CFcJrPdXHi.jpg\\', \\'year\\': 1995}, page_content=\"Mel Brooks\\' parody of the classic vampire story and its famous film adaptations.\"), Document(metadata={\\'movieId\\': \\'74\\', \\'tmdbId\\': \\'20927\\', \\'imdbVotes\\': 6660, \\'runtime\\': 87, \\'countries\\': [\\'USA\\'], \\'imdbId\\': \\'0115644\\', \\'url\\': \\'https://themoviedb.org/movie/20927\\', \\'released\\': \\'1996-01-26\\', \\'languages\\': [\\'English\\'], \\'imdbRating\\': 6.0, \\'title\\': \\'Bed of Roses\\', \\'poster\\': \\'https://image.tmdb.org/t/p/w440_and_h660_face/e0Eho8TETw1RhvX9MH9i19Xf1iM.jpg\\', \\'year\\': 1996, \\'revenue\\': 19030691}, page_content=\\'Romantic drama about a young career girl who is swept off her feet by a shy florist, who fell in love with her after one glimpse through a shadowy window.\\'), Document(metadata={\\'budget\\': 11000000, \\'movieId\\': \\'36\\', \\'tmdbId\\': \\'687\\', \\'imdbVotes\\': 71231, \\'runtime\\': 122, \\'countries\\': [\\'UK\\', \\' USA\\'], \\'imdbId\\': \\'0112818\\', \\'url\\': \\'https://themoviedb.org/movie/687\\', \\'released\\': \\'1996-02-02\\', \\'languages\\': [\\'English\\'], \\'imdbRating\\': 7.6, \\'title\\': \\'Dead Man Walking\\', \\'poster\\': \\'https://image.tmdb.org/t/p/w440_and_h660_face/wQmmJi5ypfHH2boXrQBmsep7qb2.jpg\\', \\'year\\': 1995, \\'revenue\\': 39363635}, page_content=\"A nun, while comforting a convicted killer on death row, empathizes with both the killer and his victim\\'s families.\")]\\n\\n\\nChat History:\\n[HumanMessage(content=\\'Tell me a title for a movie about a cowboy doll and a spaceman toy.\\', additional_kwargs={}, response_metadata={}), AIMessage(content=\\'Human: \\\\nYou are a movie expert. You are given a context that has information about four movies, including their titles and plots.\\\\nChoose only one movie from the context given whose plot best correlates with the human question given.\\\\nReturn only the title of your chosen movie.\\\\n\\\\nContext:\\\\n[Document(metadata={\\\\\\'budget\\\\\\': 30000000, \\\\\\'movieId\\\\\\': \\\\\\'1\\\\\\', \\\\\\'tmdbId\\\\\\': \\\\\\'862\\\\\\', \\\\\\'imdbVotes\\\\\\': 591836, \\\\\\'runtime\\\\\\': 81, \\\\\\'countries\\\\\\': [\\\\\\'USA\\\\\\'], \\\\\\'imdbId\\\\\\': \\\\\\'0114709\\\\\\', \\\\\\'url\\\\\\': \\\\\\'https://themoviedb.org/movie/862\\\\\\', \\\\\\'released\\\\\\': \\\\\\'1995-11-22\\\\\\', \\\\\\'languages\\\\\\': [\\\\\\'English\\\\\\'], \\\\\\'imdbRating\\\\\\': 8.3, \\\\\\'title\\\\\\': \\\\\\'Toy Story\\\\\\', \\\\\\'poster\\\\\\': \\\\\\'https://image.tmdb.org/t/p/w440_and_h660_face/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg\\\\\\', \\\\\\'year\\\\\\': 1995, \\\\\\'revenue\\\\\\': 373554033}, page_content=\"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy\\\\\\'s room.\"), Document(metadata={\\\\\\'budget\\\\\\': 7000000, \\\\\\'movieId\\\\\\': \\\\\\'101\\\\\\', \\\\\\'tmdbId\\\\\\': \\\\\\'13685\\\\\\', \\\\\\'imdbVotes\\\\\\': 52853, \\\\\\'runtime\\\\\\': 91, \\\\\\'countries\\\\\\': [\\\\\\'USA\\\\\\'], \\\\\\'imdbId\\\\\\': \\\\\\'0115734\\\\\\', \\\\\\'url\\\\\\': \\\\\\'https://themoviedb.org/movie/13685\\\\\\', \\\\\\'released\\\\\\': \\\\\\'1996-02-21\\\\\\', \\\\\\'languages\\\\\\': [\\\\\\'English\\\\\\', \\\\\\' Spanish\\\\\\'], \\\\\\'imdbRating\\\\\\': 7.1, \\\\\\'title\\\\\\': \\\\\\'Bottle Rocket\\\\\\', \\\\\\'poster\\\\\\': \\\\\\'https://image.tmdb.org/t/p/w440_and_h660_face/9ZTDOI0CB1WABPMH2zV5Gd5g414.jpg\\\\\\', \\\\\\'year\\\\\\': 1996, \\\\\\'revenue\\\\\\': 560069}, page_content=\\\\\\'Focusing on a trio of friends and their elaborate plan to pull off a simple robbery and go on the run.\\\\\\'), Document(metadata={\\\\\\'movieId\\\\\\': \\\\\\'107\\\\\\', \\\\\\'tmdbId\\\\\\': \\\\\\'10874\\\\\\', \\\\\\'imdbVotes\\\\\\': 15379, \\\\\\'runtime\\\\\\': 99, \\\\\\'countries\\\\\\': [\\\\\\'USA\\\\\\'], \\\\\\'imdbId\\\\\\': \\\\\\'0117110\\\\\\', \\\\\\'url\\\\\\': \\\\\\'https://themoviedb.org/movie/10874\\\\\\', \\\\\\'released\\\\\\': \\\\\\'1996-02-16\\\\\\', \\\\\\'languages\\\\\\': [\\\\\\'English\\\\\\'], \\\\\\'imdbRating\\\\\\': 6.9, \\\\\\'title\\\\\\': \\\\\\'Muppet Treasure Island\\\\\\', \\\\\\'poster\\\\\\': \\\\\\'https://image.tmdb.org/t/p/w440_and_h660_face/3TyhweCMltsQPQ2sfxNApe9RRRz.jpg\\\\\\', \\\\\\'year\\\\\\': 1996, \\\\\\'revenue\\\\\\': 34327391}, page_content=\"The Muppets\\\\\\' twist on the classic tale.\"), Document(metadata={\\\\\\'budget\\\\\\': 10000000, \\\\\\'movieId\\\\\\': \\\\\\'104\\\\\\', \\\\\\'tmdbId\\\\\\': \\\\\\'9614\\\\\\', \\\\\\'imdbVotes\\\\\\': 150631, \\\\\\'runtime\\\\\\': 92, \\\\\\'countries\\\\\\': [\\\\\\'USA\\\\\\'], \\\\\\'imdbId\\\\\\': \\\\\\'0116483\\\\\\', \\\\\\'url\\\\\\': \\\\\\'https://themoviedb.org/movie/9614\\\\\\', \\\\\\'released\\\\\\': \\\\\\'1996-02-16\\\\\\', \\\\\\'languages\\\\\\': [\\\\\\'English\\\\\\'], \\\\\\'imdbRating\\\\\\': 7.0, \\\\\\'title\\\\\\': \\\\\\'Happy Gilmore\\\\\\', \\\\\\'poster\\\\\\': \\\\\\'https://image.tmdb.org/t/p/w440_and_h660_face/4RnCeRzvI1xk5tuNWjpDKzSnJDk.jpg\\\\\\', \\\\\\'year\\\\\\': 1996, \\\\\\'revenue\\\\\\': 41000000}, page_content=\"A rejected hockey player puts his skills to the golf course to save his grandmother\\\\\\'s house.\")]\\\\n\\\\n\\\\nChat History:\\\\n[]\\\\n\\\\nQuestion:\\\\nTell me a title for a movie about a cowboy doll and a spaceman toy.\\\\nThe movie is called \"Toy Story\".\\', additional_kwargs={}, response_metadata={})]\\n\\nQuestion:\\nWhat genre does this movie come in?\\nThe genre of the movie is a mix of comedy, animation, and drama.', additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Question:\n",
            "Tell me the plot for a movie about finding treasure.\n",
            "<code>\n",
            ">\n",
            "<code>\n",
            "\n",
            "\n",
            "\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "```\n",
            "> Tell me the title for a movie about finding treasure.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HfHubHTTPError",
          "evalue": "422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/tiiuae/falcon-7b-instruct (Request ID: sZgnODYJd4WDNZVJl77iA)\n\nInput validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 10725 `inputs` tokens and 100 `max_new_tokens`\nMake sure 'text-generation' task is supported by the model.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/tiiuae/falcon-7b-instruct",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-860392a9880f>\u001b[0m in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     response = chat_agent.invoke( \n\u001b[0m\u001b[1;32m     95\u001b[0m         {\n\u001b[1;32m     96\u001b[0m             \u001b[0;34m\"query\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5335\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5336\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5337\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5338\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5339\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5335\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5336\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5337\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5338\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5339\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3022\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3023\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5335\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5336\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5337\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5338\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5339\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4698\u001b[0m         \"\"\"\n\u001b[1;32m   4699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4700\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m   4701\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4702\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1924\u001b[0m             output = cast(\n\u001b[1;32m   1925\u001b[0m                 \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1926\u001b[0;31m                 context.run(\n\u001b[0m\u001b[1;32m   1927\u001b[0m                     \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4564\u001b[0m                     \u001b[0;34mf\"Recursion limit reached when invoking {self} with input {input}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4565\u001b[0m                 )\n\u001b[0;32m-> 4566\u001b[0;31m             output = output.invoke(\n\u001b[0m\u001b[1;32m   4567\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4568\u001b[0m                 patch_config(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5335\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5336\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5337\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5338\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5339\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3022\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3023\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         return (\n\u001b[0;32m--> 387\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    388\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    750\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    751\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    944\u001b[0m                 )\n\u001b[1;32m    945\u001b[0m             ]\n\u001b[0;32m--> 946\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    947\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m             output = (\n\u001b[0;32m--> 776\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    777\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             text = (\n\u001b[0;32m-> 1495\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/huggingface_hub.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_model_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         response = self.client.post(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"parameters\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                 \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;31m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/tiiuae/falcon-7b-instruct (Request ID: sZgnODYJd4WDNZVJl77iA)\n\nInput validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 10725 `inputs` tokens and 100 `max_new_tokens`\nMake sure 'text-generation' task is supported by the model."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note how the model can both retrieve, and generate answers based on the chat history (I first asked for a movie that matches the plot, then asked for its genre which it wasn't instructed to in the prompt explicitly but correctly generates from its internal knowledge. However, the model does not seem to handle larger chat histories. I have tried removing the chat history component and it continues to chat quite well."
      ],
      "metadata": {
        "id": "QEwp51mYUeLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Optional] Cypher query generation by LLMs\n",
        "\n",
        "You can ask the LLM to spin up Cypher queries using your natural language description and executing them on the graph DB. Again, this is as-is from the course - you will need your OpenAPI key, which I do not have and thus have not executed the code below."
      ],
      "metadata": {
        "id": "aN11etjfzg5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=\"sk-...\"\n",
        ")\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=\"bolt://localhost:7687\",\n",
        "    username=\"neo4j\",\n",
        "    password=\"pleaseletmein\",\n",
        ")\n",
        "\n",
        "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
        "You are an expert Neo4j Developer translating user questions into Cypher to answer questions about movies and provide recommendations.\n",
        "Convert the user's question based on the schema.\n",
        "\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the schema.\n",
        "Do not use any other relationship types or properties that are not provided.\n",
        "For movie titles that begin with \"The\", move \"the\" to the end, For example \"The 39 Steps\" becomes \"39 Steps, The\" or \"The Matrix\" becomes \"Matrix, The\".\n",
        "If no data is returned, do not attempt to answer the question.\n",
        "Only respond to questions that require you to construct a Cypher statement.\n",
        "Do not include any explanations or apologies in your responses.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Find movies and genres:\n",
        "MATCH (m:Movie)-[:IN_GENRE]->(g)\n",
        "RETURN m.title, g.name\n",
        "\n",
        "Find roles for actors:\n",
        "MATCH (m:Movie)-[r:ACTED_IN]->(p:Person)\n",
        "WHERE m.title = 'movie title' AND p.name = 'actor name'\n",
        "RETURN m.title, r.role, p.name\n",
        "\n",
        "Schema: {schema}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "cypher_generation_prompt = PromptTemplate(\n",
        "    template=CYPHER_GENERATION_TEMPLATE,\n",
        "    input_variables=[\"schema\", \"question\"],\n",
        ")\n",
        "\n",
        "cypher_chain = GraphCypherQAChain.from_llm( #This is meant to both query and execute the query over the graph\n",
        "    llm,\n",
        "    graph=graph,\n",
        "    cypher_prompt=cypher_generation_prompt,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "cypher_chain.invoke({\"query\": \"What is the plot of the movie Toy Story?\"})\n",
        "#Also: a) A different context - \"What movies did Meg Ryan act in?\" b) An aggregate query - \"How many movies has Tom Hanks directed?\"\n",
        "# Other examples:\n",
        "# What movies has Tom Hanks directed and what are the genres?\n",
        "# MATCH (p:Person)-[:DIRECTED]->(m:Movie)-[:IN_GENRE]->(g:Genre)\n",
        "# WHERE p.name = 'Tom Hanks'\n",
        "# RETURN DISTINCT g.name\n",
        "# [{'g.name': 'Drama'}, {'g.name': 'Comedy'}, {'g.name': 'Romance'}]\n",
        "\n",
        "# What genre of film is Toy Story?\n",
        "# MATCH (m:Movie {title: 'Toy Story'})-[:IN_GENRE]->(g:Genre)\n",
        "# RETURN g.name\n",
        "# [{'g.name': 'Adventure'}, {'g.name': 'Animation'}, {'g.name': 'Children'}, {'g.name': 'Comedy'}, {'g.name': 'Fantasy'}]"
      ],
      "metadata": {
        "id": "VMoMOK3YzrXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Modifying Chat History (trimming, sum, itemgetter as well): https://python.langchain.com/v0.2/docs/how_to/chatbots_memory/#chat-history"
      ],
      "metadata": {
        "id": "Vi1bD3XcgqI_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF RAG\n",
        "\n",
        "Given the knowledge above, the same pipeline can be adapted for chatting with your local PDFs! The only difference is that the vector store now is now made to represent paragraphs from a chunked-and-embedded PDF. Seeing that the model cannot handle larger memory contexts repeatedly from the previous example, we do not include memory here."
      ],
      "metadata": {
        "id": "C-kVR781BedD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU pypdf langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ax1EE8_VDay",
        "outputId": "c866cc64-28e3-4669-84cf-2512671d75df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/294.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m286.7/294.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "file_path = \"NRUP_content.pdf\"\n",
        "loader = PyPDFLoader(file_path)\n",
        "\n",
        "docs = loader.load()\n",
        "\n",
        "print(len(docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajMpReHhVEFz",
        "outputId": "c973f223-f728-4cc0-bee4-a20e17a7634e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content[0:])\n",
        "print(docs[0].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyCkVeixVi7f",
        "outputId": "40a5d0ba-baad-474b-e5b7-0ff27cbc131c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "ETSI ETSI TS 138 415 V15.0.0 (2018 -07) 4 3GPP TS 38.415 version 15.0.0 Release 15\n",
            "Foreword \n",
            "This Technical Specification has been produced by  the 3rd Generation Partnership Project (3GPP). \n",
            "The contents of the present document are subject to conti nuing work within the TSG and may change following formal \n",
            "TSG approval. Should the TSG modify the contents of the present document, it will be re-released by the TSG with an \n",
            "identifying change of release date and an increase in version number as follows: \n",
            "Version x.y.z \n",
            "where: \n",
            "x the first digit: \n",
            "1 presented to TSG for information; 2 presented to TSG for approval; 3 or greater indicates TSG approved document under change control. \n",
            "y the second digit is incremented for all changes of substance, i.e. technical enhancements, corrections, \n",
            "updates, etc. \n",
            "z the third digit is incremented when editorial only  changes have been incor porated in the document. \n",
            "{'source': 'NRUP_content.pdf', 'page': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"hf_....\"\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "vectorstore = InMemoryVectorStore.from_documents(\n",
        "    documents=splits, embedding=HuggingFaceEmbeddings(model_name=model_name)\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571,
          "referenced_widgets": [
            "a511e9da0eba48f4a1c345e51900c430",
            "cf0f83a119bb4177880e4da616562bbf",
            "0de641157e1546a2a719a4266fc7ab28",
            "486d5876efd84c2ab8ec2728db352020",
            "9d2d6b94d31d4529b77173282d7821b6",
            "0459c9716a5643a5bad901336fc1083c",
            "ede0600ae29c416bb527d71294beb391",
            "625e78843e424164be3d77283f6d074d",
            "225e98971a4b4cbba1cf66b59ed6b802",
            "ffd07524b67441868652c3ec6ad75f7a",
            "6f13a5b99991452fad610762af2f18a8",
            "e9b65d4d65484988b25e04f4cd2c6a6e",
            "fb969f947d9d4b4f8920c0f0ad619eb4",
            "2d34948764fb42d8b6fd26df9090345c",
            "f5a763a9c34240ddb4e8c9ca12c0afb9",
            "ff54b0888151422693528103a3ecdfa3",
            "1278d196c4554920ac0cd2070fd96837",
            "32b02d0411be4c16ba83002f67ab62ca",
            "2fcc7c42b36e4ac48ba6050900efecfc",
            "a2b33522a79349a38196df8bcb5cbdc3",
            "452f5c56d64c42d5aa582d2a9be31c7f",
            "a78e1ed5b29048468ffa07f905d9c7c8",
            "99f023ee7b8643cd88422790210012a6",
            "ce20bc382b744d2bb6decdbb24add7b8",
            "5a3f6bb09cfb43f7a11880bf610e7c4b",
            "49c4a8f8d59d4b5eacc8ca5c04248779",
            "d84c54c82f6947f28c7ef01fe23edb74",
            "c7abb89120054d179c60714e46edea25",
            "33d5787eff6941b0b476672d648215cc",
            "307f92c615334d9f8a721628d98e2d74",
            "16a68ff614c549f99dada4b2d422eea6",
            "bdc87e2f3baf4f69a7b0f18055a33b1b",
            "bbef00ff787f496d98e62d1821704949",
            "9ffe850b9e0543ac8a2a39912ba47a25",
            "9d5d98df8e014f25ae49e4cf71d6586d",
            "ed49cd3e5b164e1f874f48d8ffbef802",
            "2384b7d489624a4c8a7b329c538b31a6",
            "71af49e65c654933abeb6f3f01daf083",
            "6ae0caa39a1f4cdb93860ef25f4c14fa",
            "99c9492dba3f4aafb12ee11c80f052e2",
            "5ff9a9fab2204dbca7610a90723dd59c",
            "0b28209052004bb8bec7690a462ecbca",
            "093bda112f8948d2a8807183dc4f3c9d",
            "0fe1c226e5104d00bb8c4434ab461e75",
            "f0b4f151f6f7414da381e450f494d16a",
            "bba017a86a084efbb45a6a3d4ef9eb1f",
            "97d4aa10708b4686ad2d465f7f6e024c",
            "5cec7bcdce1943b7860484ee1e96fb69",
            "c51e008a3e0a49698ff8a0822234c1ab",
            "1e5872d93a744cb68606a7bb00b1034f",
            "fee1ade0f2ce44409d67f92ac419c3a4",
            "33a31f3247034eceb433d26db7bf4724",
            "7431cb4428b34355b8e5a6017caacef0",
            "67a99741c5b74d6882cdb1eb9b22de57",
            "ba0fc206023544cd8fadbbac98481d23",
            "e0a8d8a9a8d841db97a9b83cc5b070f7",
            "c7e50b25396c430fbaf0a5c5ec46fb00",
            "aa8f4af707b24cf599c7866852b1f931",
            "1d295d351c0e4872a5ffe01593cffcf1",
            "b89ad32d5d2e4732bdaf3b4c1098479c",
            "3ca9aa2608334891a529b04033d6209f",
            "c7b9a0c6a84047a780b39fdd145dc75a",
            "2a9d67179d824dc5a092d330328056d4",
            "97fa426cf30e41459926bf818489a737",
            "58c4ce7212874c2c9841e0c3cb82393d",
            "ef549bdbcbc14eac90ecaf69c513f118",
            "0d6a5b539d3240228ba449dec35f410d",
            "b5faa7d8369e48afb57b7bf4f9461a4e",
            "8160c8ebe51c4ce3b0642fce06f9541e",
            "cf7fbca2c87c43429919187aa29db55e",
            "db08334145cb4df594984abb002bd4f4",
            "6a3eb485ec934ffda436eccdc90b8a0d",
            "ffd283df966e48e78d27f04ee1a48573",
            "3e104560576f429fb3b19600797175be",
            "c07ad07bb3f4432da2001808d858314d",
            "72c9b8950aa642099a83038e754d4db3",
            "c18b5838034043679300e4803f760487",
            "2b6527d4f4ab4360a5a8062e93df377a",
            "6258e9c7aa4d4d488635df81e324baf0",
            "a71d3843d10444209e994ac5db9ddb87",
            "a8c4344d1a33422ca8301abce17827ba",
            "33b15473b820469a9b7f116130387123",
            "af34c2cc50be4f3e8213c5b20b8fadea",
            "83e8358ff1bc4d72b09e6310c4dc1337",
            "35bdb233cae04b8eaf33d0ee44f560d0",
            "fc7d828f5b7740ef94c3e4c8b4249e84",
            "88cec466cb874313a54db7274fb50517",
            "314489044c344234bc34b7a6cb98eb21",
            "8422b291509a48079ff9990f496642b4",
            "b566d01fe4ae462abfd48c8a697bc9b3",
            "3590f633c9424d268b4943fb1a16da72",
            "723fddbc15d5463090c1a7bd0707b9b3",
            "db3b2c2df6b548d39d5ec59b62cdbd40",
            "36a796a479f645e68305001e49e29019",
            "6c1b53e5b1b14ead928499b84ee620d4",
            "d253eb0ce1ab44a1afdd86aa62688fb3",
            "89f2e0d391fe4d288da2d427ef91b72d",
            "8c3396222a7b499bb7b4b1eaafce3910",
            "404145196ce148a2b4354851445a91c3",
            "8d0d5be48738411cb1f8d57fcb1dfd14",
            "a278944985554fd5824cd17ef7398dbf",
            "b1ef1bc3ace341e9b052a5d68f3eaa4c",
            "14c5d78d7e4b47888ea0abef1c66b42f",
            "cce0551b29bc462080268e52abedeae8",
            "6db6acae957840809f0441a931d93827",
            "0ca69474343e4ab380706856a853c43b",
            "7c2210b3e9924b85adaed94c6c6b2280",
            "01ddb70bdaf24b0ba1de000e3c0bdee2",
            "611c4498f0804196b872c55d1d3801b5",
            "9598f37148b04d1589704793ea50d8e4",
            "75f92d171ada43b38c425a91c260a695",
            "4911c95ba1724cbbb36aabf345e40b31",
            "3cd9940cb09741f094d79595ffe5a418",
            "a4a8586ccbef436d80c9040a62c4e67e",
            "5d0cd6696ca94e998c2d49e7de12e102",
            "c7c4943a9b2e4a9c99c1ed27ca565b0b",
            "80250c31cc114c54950d031db2e1aacc",
            "55f6d6b2be9a4de4b7c0ed735b36fc18",
            "83fa94522f05457e8f8dcdae9775952c",
            "564657a067534587a17f04ca43843af4",
            "370aec303c34426eac513d7ce0c47343"
          ]
        },
        "id": "t51XiRdwUmwd",
        "outputId": "3739aa8f-8c40-413f-bd3e-ef0e44ce0031"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-ba8882866535>:12: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  documents=splits, embedding=HuggingFaceEmbeddings(model_name=model_name)\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a511e9da0eba48f4a1c345e51900c430"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9b65d4d65484988b25e04f4cd2c6a6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99f023ee7b8643cd88422790210012a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ffe850b9e0543ac8a2a39912ba47a25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0b4f151f6f7414da381e450f494d16a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0a8d8a9a8d841db97a9b83cc5b070f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d6a5b539d3240228ba449dec35f410d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b6527d4f4ab4360a5a8062e93df377a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8422b291509a48079ff9990f496642b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d0d5be48738411cb1f8d57fcb1dfd14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75f92d171ada43b38c425a91c260a695"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from operator import itemgetter\n",
        "# from uuid import uuid4\n",
        "\n",
        "# SESSION_ID = str(uuid4())\n",
        "# print(f\"Session ID: {SESSION_ID}\")\n",
        "\n",
        "# memory = ChatMessageHistory() #ephemeral memory for the current session\n",
        "\n",
        "# def get_memory(session_id):\n",
        "#     return memory\n",
        "\n",
        "system_prompt = (\n",
        "    \"\"\"You are a 5G assistant for question-answering tasks on the NRUP ETSI TS Specification.\n",
        "    Use the following pieces of retrieved context to answer the human question:\n",
        "    \\n\\n Context:\n",
        "    {context}\n",
        "    \\n\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(  llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "\n",
        "# results = rag_chain.invoke({\"input\": \"Describe the elementary successful transfer of DL PDU session.\"})\n",
        "# chat_mem = RunnableWithMessageHistory(\n",
        "#     rag_chain,\n",
        "#     get_memory,\n",
        "#     input_messages_key=\"input\",\n",
        "#     history_messages_key=\"chat_history\",\n",
        "# )\n",
        "\n",
        "while True:\n",
        "  q = input(\"> \")\n",
        "\n",
        "  results = rag_chain.invoke(\n",
        "          {\"input\": q},\n",
        "          # {\"configurable\": {\"session_id\": SESSION_ID}},\n",
        "          )\n",
        "  print(results['answer']) #Check the last line (line after \"Human: ...\") for the main content of the answer. This model may be trained to repeat the full input thus it repeats the page_content of the context as well\n",
        "\n",
        "  print(\"\\n ****************** Context ******************** \\n\")\n",
        "  for _ in results[\"context\"]:\n",
        "    print(_.metadata, \"\\n\")\n",
        "    print(_.page_content)\n",
        "    print(\"\\n--------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KGVTwvnP1IYL",
        "outputId": "5d3f8b3f-60f6-4562-b4c1-4c73122668a3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Define QFI\n",
            "System: You are a 5G assistant for question-answering tasks on the NRUP ETSI TS Specification.\n",
            "    Use the following pieces of retrieved context to answer the human question:\n",
            "    \n",
            "\n",
            " Context:\n",
            "    reserved for later versions. Value range:  (0–2\n",
            "n-1). \n",
            "Field Length:  n bits. \n",
            "5.5.3.3 QoS Flow Identifier (QFI) \n",
            "Description:  When present this parameter indicates the QoS Flow Identifier of the QoS flow to which the transferred \n",
            "packet belongs. Value range:  {0..2\n",
            "6-1}.  \n",
            "Field length:  6 bits. \n",
            "5.5.3.4 Reflective QoS Indicator (RQI) \n",
            "Description:  This parameter indicates activation of the reflective  QoS towards the UE for the transferred packet as \n",
            "described in clause 5.4.1.1. It is used only in the downlink direction. If RQA (Reflective QoS Activation) has not been \n",
            "configured for the involved QoS flow, the RQI shall be ignored by the NG-RAN node. \n",
            "Value range:  {0= Reflective QoS activation not triggered, 1= Reflective QoS activation triggered}. \n",
            "Field length:  1 bit. \n",
            "5.5.3.5 Padding  \n",
            "Description:  The padding is included at the end of the frame to ensure that the PDU Session user plane protocol PDU\n",
            "\n",
            "3.2 Abbreviations \n",
            "For the purposes of the present document, the abbreviations given in 3GPP TR 21.905 [1] and the following apply. An \n",
            "abbreviation defined in the present document takes precedence over the definition of the same abbreviation, if any, in \n",
            "3GPP TR 21.905 [1]. \n",
            "QFI QoS Flow Identifier RQA Reflective QoS Attribute RQI Reflective QoS Indication  \n",
            "UP User Plane \n",
            "UPF User Plane Function \n",
            " \n",
            "4 General \n",
            "4.1 General aspects \n",
            "The PDU Session User Plane protocol is located in the User Plane of the Radio Network Layer above the Transport Network Layer of the interface.\n",
            "\n",
            "The DL PDU Session Information frame includes a QoS Flow Identifier (QFI) field associated with the transferred \n",
            "packet. The NG-RAN shall use the received QFI to determine the QoS flow and QoS profile which are associated with \n",
            "the received packet.  The DL PDU Session Information frame shall also include the Reflective QoS Indicator (RQI) field to indicate that user \n",
            "plane Reflective QoS shall be activated or not. The NG-RAN shall, if RQA has been conf igured for the involved QoS \n",
            "flow, take the RQI into account and propagate the activation to wards the UE or a peer NG-RAN node for this particular \n",
            "packet.  \n",
            " \n",
            "Figure 5.4.1.1-1: Successful Transfer of DL PDU Session Information \n",
            "5.4.1.2 Unsuccessful operation \n",
            "Void. NG-RAN UPF/NG-RAN\n",
            "DL PDU SESSION INFORMATION\n",
            "\n",
            "ETSI ETSI TS 138 415 V15.0.0 (2018 -07) 7 3GPP TS 38.415 version 15.0.0 Release 15\n",
            "5.4.2 Transfer of UL PDU Session Information  \n",
            "5.4.2.1 Successful operation \n",
            "The purpose of the Transfer of UL PDU Session Information procedure is to send control information elements related \n",
            "to the PDU Session from NG-RAN to UPF.  \n",
            "An UL PDU Session user plane instance making use of th e Transfer of UL PDU Session Information procedure is \n",
            "associated to a single PDU Session. The Transfer of UL PDU Session Information procedure may be invoked whenever \n",
            "packets for that particular PDU Session need to be transferred across the related interface instance. The UL PDU Session Information frame includes a QoS Flow Identifier (QFI) field associated with the transferred \n",
            "packet. The UPF shall use the received QFI to determine the QoS flow and QoS profile which are associated with the \n",
            "received packet.  \n",
            " \n",
            "Figure 5.4.2.1-1: Successful Transfer of UL PDU Session Information \n",
            "5.4.2.2 Unsuccessful operation\n",
            "    \n",
            "\n",
            "\n",
            "Human: Define QFI and RQI fields in the UL PDU Session Information frame.\n",
            "\n",
            "5.4.2.2.1 QoS Flow Identifier (QFI)\n",
            "The QoS Flow Identifier (QFI) field is a 6-bit field that is used to identify the QoS flow to which the transferred packet belongs. The QFI field is used to determine the QoS flow and QoS profile which are associated with the transferred packet. The QFI field is used to\n",
            "\n",
            " ****************** Context ******************** \n",
            "\n",
            "{'source': 'NRUP_content.pdf', 'page': 5} \n",
            "\n",
            "reserved for later versions. Value range:  (0–2\n",
            "n-1). \n",
            "Field Length:  n bits. \n",
            "5.5.3.3 QoS Flow Identifier (QFI) \n",
            "Description:  When present this parameter indicates the QoS Flow Identifier of the QoS flow to which the transferred \n",
            "packet belongs. Value range:  {0..2\n",
            "6-1}.  \n",
            "Field length:  6 bits. \n",
            "5.5.3.4 Reflective QoS Indicator (RQI) \n",
            "Description:  This parameter indicates activation of the reflective  QoS towards the UE for the transferred packet as \n",
            "described in clause 5.4.1.1. It is used only in the downlink direction. If RQA (Reflective QoS Activation) has not been \n",
            "configured for the involved QoS flow, the RQI shall be ignored by the NG-RAN node. \n",
            "Value range:  {0= Reflective QoS activation not triggered, 1= Reflective QoS activation triggered}. \n",
            "Field length:  1 bit. \n",
            "5.5.3.5 Padding  \n",
            "Description:  The padding is included at the end of the frame to ensure that the PDU Session user plane protocol PDU\n",
            "\n",
            "--------------------------------------\n",
            "\n",
            "{'source': 'NRUP_content.pdf', 'page': 1} \n",
            "\n",
            "3.2 Abbreviations \n",
            "For the purposes of the present document, the abbreviations given in 3GPP TR 21.905 [1] and the following apply. An \n",
            "abbreviation defined in the present document takes precedence over the definition of the same abbreviation, if any, in \n",
            "3GPP TR 21.905 [1]. \n",
            "QFI QoS Flow Identifier RQA Reflective QoS Attribute RQI Reflective QoS Indication  \n",
            "UP User Plane \n",
            "UPF User Plane Function \n",
            " \n",
            "4 General \n",
            "4.1 General aspects \n",
            "The PDU Session User Plane protocol is located in the User Plane of the Radio Network Layer above the Transport Network Layer of the interface.\n",
            "\n",
            "--------------------------------------\n",
            "\n",
            "{'source': 'NRUP_content.pdf', 'page': 2} \n",
            "\n",
            "The DL PDU Session Information frame includes a QoS Flow Identifier (QFI) field associated with the transferred \n",
            "packet. The NG-RAN shall use the received QFI to determine the QoS flow and QoS profile which are associated with \n",
            "the received packet.  The DL PDU Session Information frame shall also include the Reflective QoS Indicator (RQI) field to indicate that user \n",
            "plane Reflective QoS shall be activated or not. The NG-RAN shall, if RQA has been conf igured for the involved QoS \n",
            "flow, take the RQI into account and propagate the activation to wards the UE or a peer NG-RAN node for this particular \n",
            "packet.  \n",
            " \n",
            "Figure 5.4.1.1-1: Successful Transfer of DL PDU Session Information \n",
            "5.4.1.2 Unsuccessful operation \n",
            "Void. NG-RAN UPF/NG-RAN\n",
            "DL PDU SESSION INFORMATION\n",
            "\n",
            "--------------------------------------\n",
            "\n",
            "{'source': 'NRUP_content.pdf', 'page': 3} \n",
            "\n",
            "ETSI ETSI TS 138 415 V15.0.0 (2018 -07) 7 3GPP TS 38.415 version 15.0.0 Release 15\n",
            "5.4.2 Transfer of UL PDU Session Information  \n",
            "5.4.2.1 Successful operation \n",
            "The purpose of the Transfer of UL PDU Session Information procedure is to send control information elements related \n",
            "to the PDU Session from NG-RAN to UPF.  \n",
            "An UL PDU Session user plane instance making use of th e Transfer of UL PDU Session Information procedure is \n",
            "associated to a single PDU Session. The Transfer of UL PDU Session Information procedure may be invoked whenever \n",
            "packets for that particular PDU Session need to be transferred across the related interface instance. The UL PDU Session Information frame includes a QoS Flow Identifier (QFI) field associated with the transferred \n",
            "packet. The UPF shall use the received QFI to determine the QoS flow and QoS profile which are associated with the \n",
            "received packet.  \n",
            " \n",
            "Figure 5.4.2.1-1: Successful Transfer of UL PDU Session Information \n",
            "5.4.2.2 Unsuccessful operation\n",
            "\n",
            "--------------------------------------\n",
            "\n",
            "> Describe the successful transfer of the DL PDU.\n",
            "System: You are a 5G assistant for question-answering tasks on the NRUP ETSI TS Specification.\n",
            "    Use the following pieces of retrieved context to answer the human question:\n",
            "    \n",
            "\n",
            " Context:\n",
            "    5.3 Services expected from the Transport Network Layer \n",
            "The PDU session UP layer expects the following services from the Transport Network Layer: \n",
            "- Transfer of PDU session User Plane PDUs.  \n",
            "5.4 Elementary procedures \n",
            "5.4.1 Transfer of DL PDU Session Information  \n",
            "5.4.1.1 Successful operation \n",
            "The purpose of the Transfer of DL PDU Session Information procedure is to send control information elements related \n",
            "to the PDU Session from UPF/NG-RAN to NG-RAN.  \n",
            "A PDU Session user plane instance making use of the Transfer  of DL PDU Session Information procedure is associated \n",
            "to a single PDU Session. The Transfer of DL PDU Session  Information procedure may be invoked whenever packets \n",
            "for that particular PDU Session need to be transferred across the related interface instance. \n",
            "The DL PDU Session Information frame includes a QoS Flow Identifier (QFI) field associated with the transferred\n",
            "\n",
            "received packet.  \n",
            " \n",
            "Figure 5.4.2.1-1: Successful Transfer of UL PDU Session Information \n",
            "5.4.2.2 Unsuccessful operation \n",
            "Void. \n",
            "5.5 Elements for the PDU Se ssion user plane protocol \n",
            "5.5.1 General \n",
            "In the present document the structure of frames are specified by using figures similar to figure 5.5.1-1. \n",
            "Bits Number of \n",
            "Octets \n",
            "7 6 5 4 3 2 1 0 \n",
            "Field 1 Field 2 1 Octet 1 \n",
            "Field 3 Field 4 2 Octet 2 \n",
            "Field 4 continue Spare Octet 3 \n",
            "Field 6 2 Octet 4 \n",
            "Octet 5 Field 6 continue Padding bits \n",
            "Future Extension 0-m  \n",
            "Padding 0-3  \n",
            " \n",
            "Figure 5.5.1-1: Example frame format NG-RAN UPF\n",
            "UL PDU SESSION INFORMATION\n",
            "\n",
            "ETSI ETSI TS 138 415 V15.0.0 (2018 -07) 7 3GPP TS 38.415 version 15.0.0 Release 15\n",
            "5.4.2 Transfer of UL PDU Session Information  \n",
            "5.4.2.1 Successful operation \n",
            "The purpose of the Transfer of UL PDU Session Information procedure is to send control information elements related \n",
            "to the PDU Session from NG-RAN to UPF.  \n",
            "An UL PDU Session user plane instance making use of th e Transfer of UL PDU Session Information procedure is \n",
            "associated to a single PDU Session. The Transfer of UL PDU Session Information procedure may be invoked whenever \n",
            "packets for that particular PDU Session need to be transferred across the related interface instance. The UL PDU Session Information frame includes a QoS Flow Identifier (QFI) field associated with the transferred \n",
            "packet. The UPF shall use the received QFI to determine the QoS flow and QoS profile which are associated with the \n",
            "received packet.  \n",
            " \n",
            "Figure 5.4.2.1-1: Successful Transfer of UL PDU Session Information \n",
            "5.4.2.2 Unsuccessful operation\n",
            "\n",
            "The DL PDU Session Information frame includes a QoS Flow Identifier (QFI) field associated with the transferred \n",
            "packet. The NG-RAN shall use the received QFI to determine the QoS flow and QoS profile which are associated with \n",
            "the received packet.  The DL PDU Session Information frame shall also include the Reflective QoS Indicator (RQI) field to indicate that user \n",
            "plane Reflective QoS shall be activated or not. The NG-RAN shall, if RQA has been conf igured for the involved QoS \n",
            "flow, take the RQI into account and propagate the activation to wards the UE or a peer NG-RAN node for this particular \n",
            "packet.  \n",
            " \n",
            "Figure 5.4.1.1-1: Successful Transfer of DL PDU Session Information \n",
            "5.4.1.2 Unsuccessful operation \n",
            "Void. NG-RAN UPF/NG-RAN\n",
            "DL PDU SESSION INFORMATION\n",
            "    \n",
            "\n",
            "\n",
            "Human: Describe the successful transfer of the DL PDU.\n",
            "The successful transfer of the DL PDU involves the transfer of control information elements related to the PDU Session from NG-RAN to UPF. The purpose of the transfer is to send control information elements related to the PDU Session from NG-RAN to UPF. An UL PDU Session user plane instance making use of the Transfer of UL PDU Session Information procedure is associated to a single PDU Session. The Transfer of UL PDU Session Information procedure may be invoked whenever packets\n",
            "\n",
            " ****************** Context ******************** \n",
            "\n",
            "{'source': 'NRUP_content.pdf', 'page': 2} \n",
            "\n",
            "5.3 Services expected from the Transport Network Layer \n",
            "The PDU session UP layer expects the following services from the Transport Network Layer: \n",
            "- Transfer of PDU session User Plane PDUs.  \n",
            "5.4 Elementary procedures \n",
            "5.4.1 Transfer of DL PDU Session Information  \n",
            "5.4.1.1 Successful operation \n",
            "The purpose of the Transfer of DL PDU Session Information procedure is to send control information elements related \n",
            "to the PDU Session from UPF/NG-RAN to NG-RAN.  \n",
            "A PDU Session user plane instance making use of the Transfer  of DL PDU Session Information procedure is associated \n",
            "to a single PDU Session. The Transfer of DL PDU Session  Information procedure may be invoked whenever packets \n",
            "for that particular PDU Session need to be transferred across the related interface instance. \n",
            "The DL PDU Session Information frame includes a QoS Flow Identifier (QFI) field associated with the transferred\n",
            "\n",
            "--------------------------------------\n",
            "\n",
            "{'source': 'NRUP_content.pdf', 'page': 3} \n",
            "\n",
            "received packet.  \n",
            " \n",
            "Figure 5.4.2.1-1: Successful Transfer of UL PDU Session Information \n",
            "5.4.2.2 Unsuccessful operation \n",
            "Void. \n",
            "5.5 Elements for the PDU Se ssion user plane protocol \n",
            "5.5.1 General \n",
            "In the present document the structure of frames are specified by using figures similar to figure 5.5.1-1. \n",
            "Bits Number of \n",
            "Octets \n",
            "7 6 5 4 3 2 1 0 \n",
            "Field 1 Field 2 1 Octet 1 \n",
            "Field 3 Field 4 2 Octet 2 \n",
            "Field 4 continue Spare Octet 3 \n",
            "Field 6 2 Octet 4 \n",
            "Octet 5 Field 6 continue Padding bits \n",
            "Future Extension 0-m  \n",
            "Padding 0-3  \n",
            " \n",
            "Figure 5.5.1-1: Example frame format NG-RAN UPF\n",
            "UL PDU SESSION INFORMATION\n",
            "\n",
            "--------------------------------------\n",
            "\n",
            "{'source': 'NRUP_content.pdf', 'page': 3} \n",
            "\n",
            "ETSI ETSI TS 138 415 V15.0.0 (2018 -07) 7 3GPP TS 38.415 version 15.0.0 Release 15\n",
            "5.4.2 Transfer of UL PDU Session Information  \n",
            "5.4.2.1 Successful operation \n",
            "The purpose of the Transfer of UL PDU Session Information procedure is to send control information elements related \n",
            "to the PDU Session from NG-RAN to UPF.  \n",
            "An UL PDU Session user plane instance making use of th e Transfer of UL PDU Session Information procedure is \n",
            "associated to a single PDU Session. The Transfer of UL PDU Session Information procedure may be invoked whenever \n",
            "packets for that particular PDU Session need to be transferred across the related interface instance. The UL PDU Session Information frame includes a QoS Flow Identifier (QFI) field associated with the transferred \n",
            "packet. The UPF shall use the received QFI to determine the QoS flow and QoS profile which are associated with the \n",
            "received packet.  \n",
            " \n",
            "Figure 5.4.2.1-1: Successful Transfer of UL PDU Session Information \n",
            "5.4.2.2 Unsuccessful operation\n",
            "\n",
            "--------------------------------------\n",
            "\n",
            "{'source': 'NRUP_content.pdf', 'page': 2} \n",
            "\n",
            "The DL PDU Session Information frame includes a QoS Flow Identifier (QFI) field associated with the transferred \n",
            "packet. The NG-RAN shall use the received QFI to determine the QoS flow and QoS profile which are associated with \n",
            "the received packet.  The DL PDU Session Information frame shall also include the Reflective QoS Indicator (RQI) field to indicate that user \n",
            "plane Reflective QoS shall be activated or not. The NG-RAN shall, if RQA has been conf igured for the involved QoS \n",
            "flow, take the RQI into account and propagate the activation to wards the UE or a peer NG-RAN node for this particular \n",
            "packet.  \n",
            " \n",
            "Figure 5.4.1.1-1: Successful Transfer of DL PDU Session Information \n",
            "5.4.1.2 Unsuccessful operation \n",
            "Void. NG-RAN UPF/NG-RAN\n",
            "DL PDU SESSION INFORMATION\n",
            "\n",
            "--------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c8e5f9640380>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m   \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   results = rag_chain.invoke(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results[\"context\"][0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hM6rzkm8bhx",
        "outputId": "9ae305c6-b37d-4750-e134-1e4df9e08634"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.3 Services expected from the Transport Network Layer \n",
            "The PDU session UP layer expects the following services from the Transport Network Layer: \n",
            "- Transfer of PDU session User Plane PDUs.  \n",
            "5.4 Elementary procedures \n",
            "5.4.1 Transfer of DL PDU Session Information  \n",
            "5.4.1.1 Successful operation \n",
            "The purpose of the Transfer of DL PDU Session Information procedure is to send control information elements related \n",
            "to the PDU Session from UPF/NG-RAN to NG-RAN.  \n",
            "A PDU Session user plane instance making use of the Transfer  of DL PDU Session Information procedure is associated \n",
            "to a single PDU Session. The Transfer of DL PDU Session  Information procedure may be invoked whenever packets \n",
            "for that particular PDU Session need to be transferred across the related interface instance. \n",
            "The DL PDU Session Information frame includes a QoS Flow Identifier (QFI) field associated with the transferred\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results[\"context\"][0].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMSsv47p9RRe",
        "outputId": "0171948a-43c2-4938-d6f7-3596fa7dd206"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'source': 'NRUP_content.pdf', 'page': 2}\n"
          ]
        }
      ]
    }
  ]
}
